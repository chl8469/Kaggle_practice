{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxQ2YTAv4tB-"
   },
   "source": [
    "# Week 3\n",
    "\n",
    "### Context\n",
    "#### k-Fold Technic\n",
    "- Label Postprocess only binary classification\n",
    "\n",
    "#### Feature Selection\n",
    "- Permutation Importance\n",
    "\n",
    "#### AutoML\n",
    "+ NNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAfXTYpj5ysB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import multiprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n_cpus = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '../'\n",
    "\n",
    "train_path = join(BASE_DIR, 'data', 'MDC14', 'train.csv')\n",
    "test_path  = join(BASE_DIR, 'data', 'MDC14', 'test.csv')\n",
    "\n",
    "data = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "label = data['credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 컬럼 제거\n",
    "data.drop(columns=['index', 'credit'], inplace=True)\n",
    "test.drop(columns=['index'],           inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [c for c, t in zip(data.dtypes.index, data.dtypes) if t == 'O'] \n",
    "num_columns = [c for c    in data.columns if c not in cat_columns]\n",
    "\n",
    "print('Categorical Columns: \\n{}\\n'.format(cat_columns))\n",
    "print('Numeric Columns: \\n{}'.format(num_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 라벨 데이터 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리 프로세스 함수로 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "def preprocess(x_train, x_valid, x_test):\n",
    "    tmp_x_train = x_train.copy()\n",
    "    tmp_x_valid = x_valid.copy()\n",
    "    tmp_x_test  = x_test.copy()\n",
    "    \n",
    "    tmp_x_train.reset_index(drop=True, inplace=True)\n",
    "    tmp_x_valid.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 결측치 처리\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    tmp_x_train[cat_columns] = imputer.fit_transform(tmp_x_train[cat_columns])\n",
    "    tmp_x_valid[cat_columns] = imputer.transform(tmp_x_valid[cat_columns])\n",
    "    tmp_x_test[cat_columns]  = imputer.transform(tmp_x_test[cat_columns])\n",
    "    \n",
    "    # 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    tmp_x_train[num_columns] = scaler.fit_transform(tmp_x_train[num_columns])\n",
    "    tmp_x_valid[num_columns] = scaler.transform(tmp_x_valid[num_columns])\n",
    "    tmp_x_test[num_columns]  = scaler.transform(tmp_x_test[num_columns])\n",
    "\n",
    "    # 인코딩\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    ohe.fit(tmp_x_train[cat_columns])\n",
    "    \n",
    "    tmp_x_train_cat = pd.DataFrame(ohe.transform(tmp_x_train[cat_columns]))\n",
    "    tmp_x_valid_cat = pd.DataFrame(ohe.transform(tmp_x_valid[cat_columns]))\n",
    "    tmp_x_test_cat  = pd.DataFrame(ohe.transform(tmp_x_test[cat_columns]))\n",
    "    \n",
    "    tmp_x_train.drop(columns=cat_columns, inplace=True)\n",
    "    tmp_x_valid.drop(columns=cat_columns, inplace=True)\n",
    "    tmp_x_test.drop(columns=cat_columns, inplace=True)\n",
    "    \n",
    "    tmp_x_train = pd.concat([tmp_x_train, tmp_x_train_cat], axis=1)\n",
    "    tmp_x_valid = pd.concat([tmp_x_valid, tmp_x_valid_cat], axis=1)\n",
    "    tmp_x_test  = pd.concat([tmp_x_test, tmp_x_test_cat], axis=1)\n",
    "    \n",
    "    return tmp_x_train, tmp_x_valid, tmp_x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Fold technic\n",
    "### Label Postprocessing\n",
    "- 이진 분류인 경우 Threshold 값을 최적화하여 조금 더 좋은 성능을 이끌어낼 수 있습니다. \n",
    "- k-Fold를 활용하여 train 라벨에서 가장 좋은 threshold 값을 찾아, 각 라벨 생성을 최적화 할 수 있습니다.\n",
    "\n",
    "1. train 셋에 대해서도 라벨을 모읍니다.\n",
    "2. y_train, y_train_pred 값으로 최적 threshold 값을 찾습니다.\n",
    "3. threshold 를 0.01 단위로 0~1 사이값을 변경해가면서 평가 지표에 대해 평가합니다.\n",
    "4. 그 중 가장 높은 평가 지표를 갖는 threshold를 선택합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클래스가 0, 1인 데이터만 추출하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_data = data.loc[label < 2,:]\n",
    "binary_label = label.loc[label < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_data.reset_index(inplace=True, drop=True)\n",
    "binary_label.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_data.shape, binary_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics  import log_loss, accuracy_score\n",
    "\n",
    "val_scores = list()\n",
    "oof_train = np.zeros((binary_data.shape[0], 2))\n",
    "oof_pred  = np.zeros((test.shape[0], 2))\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(binary_data, binary_label)):\n",
    "    x_train, y_train = binary_data.iloc[trn_idx, :], binary_label.iloc[trn_idx,]\n",
    "    x_valid, y_valid = binary_data.iloc[val_idx, :], binary_label.iloc[val_idx,]\n",
    "    \n",
    "    # 전처리\n",
    "    x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n",
    "    \n",
    "    # 모델 정의\n",
    "    model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, n_jobs=n_cpus-1)\n",
    "    \n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 훈련, 검증 데이터 accuracy_score 확인\n",
    "    trn_acc = accuracy_score(y_train, (model.predict_proba(x_train)[:, 1] > 0.5).astype(int))\n",
    "    val_acc = accuracy_score(y_valid, (model.predict_proba(x_valid)[:, 1] > 0.5).astype(int))\n",
    "    print('{} Fold, train accuracy_score : {:.4f}4, validation accuracy_score : {:.4f}'.format(i, trn_acc, val_acc))\n",
    "    \n",
    "    val_scores.append(val_acc)\n",
    "    \n",
    "    _, x_data, _ = preprocess(binary_data.iloc[trn_idx, :], binary_data, test)\n",
    "    oof_train += model.predict_proba(x_data) / 5\n",
    "    oof_pred  += model.predict_proba(x_test) / 5\n",
    "    \n",
    "\n",
    "# 교차 검증 accuracy_score 평균 계산하기\n",
    "print('Cross Validation Score : {:.5f}'.format(np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def threshold_search(y_true, y_proba):\n",
    "    # 0 ~ 1 사이에서 0.01 단위로 threhold 생성\n",
    "    thresholds = np.linspace(0, 1, 101) \n",
    "\n",
    "    # 각 threshold 마다 f1_score 측정합니다.\n",
    "    f1_scores   = np.array([ f1_score(y_true, (y_proba > t).astype(np.int)) \n",
    "                             for t in thresholds ])\n",
    "    best_score = np.max(f1_scores)\n",
    "\n",
    "    # 가장 높은 f1_score를 갖는 threshold를 택합니다.\n",
    "    best_th = thresholds[np.argmax(f1_scores)]\n",
    "    return best_th, best_score\n",
    "\n",
    "def scoring(y_true, y_proba, verbose=True):\n",
    "    # 반복적으로 kFold를 진행할 수 있습니다.\n",
    "    rkf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "    scores = []\n",
    "    ths = []\n",
    "    for train_index, test_index in rkf.split(y_true, y_true):\n",
    "        y_prob_train, y_prob_test = y_proba[train_index], y_proba[test_index]\n",
    "        y_true_train, y_true_test = y_true[train_index], y_true[test_index]\n",
    "\n",
    "        best_threshold, sc = threshold_search(y_true_train, y_prob_train)\n",
    "        \n",
    "        ths.append(best_threshold)\n",
    "        scores.append(sc)\n",
    "\n",
    "    # 최적 threshold들의 평균 값으로 최종 threshold를 택합니다.\n",
    "    best_th = np.mean(ths)\n",
    "    score = np.mean(scores)\n",
    "\n",
    "    if verbose: print(f'Best threshold: {np.round(best_th, 4)}, Score: {np.round(score, 5)}')\n",
    "\n",
    "    return best_th, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_th, _ = scoring(binary_label, oof_train[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 찾은 threhold 값으로 Validation Score 재 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores = list()\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(binary_data, binary_label)):\n",
    "    x_train, y_train = binary_data.iloc[trn_idx, :], binary_label.iloc[trn_idx,]\n",
    "    x_valid, y_valid = binary_data.iloc[val_idx, :], binary_label.iloc[val_idx,]\n",
    "    \n",
    "    # 전처리\n",
    "    x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n",
    "    \n",
    "    # 모델 정의\n",
    "    model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, n_jobs=n_cpus-1)\n",
    "    \n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 훈련, 검증 데이터 accuracy_score 확인\n",
    "    trn_acc = accuracy_score(y_train, (model.predict_proba(x_train)[:, 1] > best_th).astype(int))\n",
    "    val_acc = accuracy_score(y_valid, (model.predict_proba(x_valid)[:, 1] > best_th).astype(int))\n",
    "    print('{} Fold, train accuracy_score : {:.4f}4, validation accuracy_score : {:.4f}'.format(i, trn_acc, val_acc))\n",
    "    \n",
    "    val_scores.append(val_acc)\n",
    "\n",
    "# 교차 검증 accuracy_score 평균 계산하기\n",
    "print('Cross Validation Score : {:.5f}'.format(np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "### Permutation Importance\n",
    "- 좋은 변수를 선택하는 방법 중 최근에 많이 사용되는 Permutation Importance에 대해 알아보겠습니다. \n",
    "- Permutation Importance의 기본 원리는 어떤 변수를 임의로 섞어 그 중 타겟 변수에 영향을 많이 주는 변수를 탐색합니다.\n",
    "- 예를 들어 타겟 변수를 예측하기 좋은 변수는 임의로 섞었을 경우 모델의 성능이 많이 떨어지게되는데, 이러한 방식으로 좋은 변수를 선별해 냅니다.\n",
    "\n",
    "$$ i_j=s-{{1}\\over{K}}\\sum^K_{k=1}s_{k,j}$$\n",
    "\n",
    "$$ s=원본\\ 데이터셋의\\ 점수 [분류(Accuracy)| 회귀(R^2)] $$\n",
    "$$ j=변수(feature)\\ 인덱스$$\n",
    "$$ k=반복\\ 인덱스$$\n",
    "\n",
    "\n",
    "\n",
    "#### ref\n",
    "Permutation Importance: https://scikit-learn.org/stable/modules/permutation_importance.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(data, label, \n",
    "                                                      test_size=0.3,\n",
    "                                                      random_state=42,\n",
    "                                                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, _ = preprocess(x_train, x_valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=(n_cpus-1))\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "r = permutation_importance(model, x_valid, y_valid,\n",
    "                           n_repeats=10,\n",
    "                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{x_valid.columns[i]:<8}: \"\n",
    "               f\"{r.importances_mean[i]:.3f}\"\n",
    "               f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
