{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e7705171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder, PowerTransformer, StandardScaler, \\\n",
    "                                    MinMaxScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, log_loss, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from function_dt_check import time_checker\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "import json\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "68870059",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.family'] = 'Hancom Gothic'\n",
    "plt.style.use('bmh')\n",
    "plt.rc('font',size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ed6feb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/HwaLang/Desktop/python/T academy/Kaggle_camp/'\n",
    "train_path = os.path.join(BASE_DIR, 'data', 'MDC14', 'train.csv')\n",
    "test_path  = os.path.join(BASE_DIR, 'data', 'MDC14', 'test.csv')\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "submission = pd.read_csv(f'{BASE_DIR}/data/MDC14/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ec6f3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna('NaN', inplace=True) \n",
    "test.fillna('NaN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "15ca0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train['family_size'] <= 7)]\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "27a347f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['FLAG_MOBIL'], axis=1, inplace=True)\n",
    "test.drop(['FLAG_MOBIL'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "869e2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['DAYS_EMPLOYED'] = train['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "test['DAYS_EMPLOYED'] = test['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9a8b0e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['DAYS_BIRTH', 'begin_month', 'DAYS_EMPLOYED']\n",
    "for feat in feats:\n",
    "    train[feat]=np.abs(train[feat])\n",
    "    test[feat]=np.abs(test[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cd4bd094",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    # before_EMPLOYED: 고용되기 전까지의 일수\n",
    "    df['before_EMPLOYED'] = df['DAYS_BIRTH'] - df['DAYS_EMPLOYED']\n",
    "    df['income_total_befofeEMP_ratio'] = df['income_total'] / df['before_EMPLOYED']\n",
    "    df['before_EMPLOYED_m'] = np.floor(df['before_EMPLOYED'] / 30) - ((np.floor(df['before_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "    df['before_EMPLOYED_w'] = np.floor(df['before_EMPLOYED'] / 7) - ((np.floor(df['before_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "    \n",
    "    #DAYS_BIRTH 파생변수- Age(나이), 태어난 월, 태어난 주(출생연도의 n주차)\n",
    "    df['Age'] = df['DAYS_BIRTH'] // 365\n",
    "    df['DAYS_BIRTH_m'] = np.floor(df['DAYS_BIRTH'] / 30) - ((np.floor(df['DAYS_BIRTH'] / 30) / 12).astype(int) * 12)\n",
    "    df['DAYS_BIRTH_w'] = np.floor(df['DAYS_BIRTH'] / 7) - ((np.floor(df['DAYS_BIRTH'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "    \n",
    "    #DAYS_EMPLOYED_m 파생변수- EMPLOYED(근속연수), DAYS_EMPLOYED_m(고용된 달) ,DAYS_EMPLOYED_w(고용된 주(고용연도의 n주차))  \n",
    "    df['EMPLOYED'] = df['DAYS_EMPLOYED'] // 365\n",
    "    df['DAYS_EMPLOYED_m'] = np.floor(df['DAYS_EMPLOYED'] / 30) - ((np.floor(df['DAYS_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "    df['DAYS_EMPLOYED_w'] = np.floor(df['DAYS_EMPLOYED'] / 7) - ((np.floor(df['DAYS_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "    #ability: 소득/(살아온 일수+ 근무일수)\n",
    "    df['ability'] = df['income_total'] / (df['DAYS_BIRTH'] + df['DAYS_EMPLOYED'])\n",
    "    \n",
    "    #income_mean: 소득/ 가족 수\n",
    "    df['income_mean'] = df['income_total'] / df['family_size']\n",
    "    \n",
    "    #ID 생성: 각 컬럼의 값들을 더해서 고유한 사람을 파악(*한 사람이 여러 개 카드를 만들 가능성을 고려해 begin_month는 제외함)\n",
    "    df['ID'] = \\\n",
    "    df['child_num'].astype(str) + '_' + df['income_total'].astype(str) + '_' +\\\n",
    "    df['DAYS_BIRTH'].astype(str) + '_' + df['DAYS_EMPLOYED'].astype(str) + '_' +\\\n",
    "    df['work_phone'].astype(str) + '_' + df['phone'].astype(str) + '_' +\\\n",
    "    df['email'].astype(str) + '_' + df['family_size'].astype(str) + '_' +\\\n",
    "    df['gender'].astype(str) + '_' + df['car'].astype(str) + '_' +\\\n",
    "    df['reality'].astype(str) + '_' + df['income_type'].astype(str) + '_' +\\\n",
    "    df['edu_type'].astype(str) + '_' + df['family_type'].astype(str) + '_' +\\\n",
    "    df['house_type'].astype(str) + '_' + df['occyp_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "55231c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED',]\n",
    "train.drop(cols, axis=1, inplace=True)\n",
    "test.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d770dc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Numerical features:  19\n",
      "Number of Categorical features:  9\n"
     ]
    }
   ],
   "source": [
    "numerical_feats = train.dtypes[train.dtypes != \"object\"].index.tolist()\n",
    "numerical_feats.remove('credit')\n",
    "print(\"Number of Numerical features: \", len(numerical_feats))\n",
    "\n",
    "categorical_feats = train.dtypes[train.dtypes == \"object\"].index.tolist()\n",
    "print(\"Number of Categorical features: \", len(categorical_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "abcd1512",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    df['income_total'] = np.log1p(1+df['income_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3f2072cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder(categorical_feats)\n",
    "train[categorical_feats] = encoder.fit_transform(train[categorical_feats], train['credit'])\n",
    "test[categorical_feats] = encoder.transform(test[categorical_feats])\n",
    "\n",
    "train['ID'] = train['ID'].astype('int64')\n",
    "test['ID'] = test['ID'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "998e423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_train = train.drop(['credit'], axis=1)\n",
    "kmeans = KMeans(n_clusters=36, random_state=42).fit(kmeans_train)\n",
    "train['cluster'] = kmeans.predict(kmeans_train)\n",
    "test['cluster'] = kmeans.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "64876878",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feats.remove('income_total')\n",
    "scaler = StandardScaler()\n",
    "train[numerical_feats] = scaler.fit_transform(train[numerical_feats])\n",
    "test[numerical_feats] = scaler.transform(test[numerical_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cd3ea96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainkeys = train.keys().to_list()\n",
    "trainkeys.remove('credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dbef2229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>DAYS_BIRTH_m</th>\n",
       "      <th>DAYS_BIRTH_w</th>\n",
       "      <th>EMPLOYED</th>\n",
       "      <th>DAYS_EMPLOYED_m</th>\n",
       "      <th>DAYS_EMPLOYED_w</th>\n",
       "      <th>ability</th>\n",
       "      <th>income_mean</th>\n",
       "      <th>ID</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.731942</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.218505</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452826</td>\n",
       "      <td>0.442795</td>\n",
       "      <td>-0.443485</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>-1.230046</td>\n",
       "      <td>-1.077087</td>\n",
       "      <td>-0.032496</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.731811</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.419174</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.060773</td>\n",
       "      <td>0.442795</td>\n",
       "      <td>-0.443485</td>\n",
       "      <td>-0.250471</td>\n",
       "      <td>-0.424295</td>\n",
       "      <td>-1.077087</td>\n",
       "      <td>1.190137</td>\n",
       "      <td>-0.254157</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.731680</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13.017007</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763069</td>\n",
       "      <td>-1.582567</td>\n",
       "      <td>0.451504</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>-0.424295</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>1.186515</td>\n",
       "      <td>1.693108</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.731549</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.218505</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192277</td>\n",
       "      <td>1.310808</td>\n",
       "      <td>1.346494</td>\n",
       "      <td>-0.094880</td>\n",
       "      <td>1.187206</td>\n",
       "      <td>0.629874</td>\n",
       "      <td>0.101168</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.731418</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11.967193</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192277</td>\n",
       "      <td>1.021471</td>\n",
       "      <td>-1.338475</td>\n",
       "      <td>-0.094880</td>\n",
       "      <td>1.455790</td>\n",
       "      <td>-1.077087</td>\n",
       "      <td>-0.282885</td>\n",
       "      <td>-0.305401</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  gender  car  reality  income_total  income_type  edu_type  \\\n",
       "0 -1.731942       1    1        1     12.218505            1         1   \n",
       "1 -1.731811       1    1        2     12.419174            1         2   \n",
       "2 -1.731680       2    2        2     13.017007            2         1   \n",
       "3 -1.731549       1    1        2     12.218505            1         2   \n",
       "4 -1.731418       1    2        2     11.967193            3         1   \n",
       "\n",
       "   family_type  house_type  work_phone  ...       Age  DAYS_BIRTH_m  \\\n",
       "0            1           1   -0.538321  ... -0.452826      0.442795   \n",
       "1            2           2   -0.538321  ... -1.060773      0.442795   \n",
       "2            1           2   -0.538321  ...  0.763069     -1.582567   \n",
       "3            1           2   -0.538321  ... -0.192277      1.310808   \n",
       "4            1           2   -0.538321  ... -0.192277      1.021471   \n",
       "\n",
       "   DAYS_BIRTH_w  EMPLOYED  DAYS_EMPLOYED_m  DAYS_EMPLOYED_w   ability  \\\n",
       "0     -0.443485  0.994253        -1.230046        -1.077087 -0.032496   \n",
       "1     -0.443485 -0.250471        -0.424295        -1.077087  1.190137   \n",
       "2      0.451504  0.994253        -0.424295        -0.223607  1.186515   \n",
       "3      1.346494 -0.094880         1.187206         0.629874  0.101168   \n",
       "4     -1.338475 -0.094880         1.455790        -1.077087 -0.282885   \n",
       "\n",
       "   income_mean  ID  cluster  \n",
       "0     0.002062   1       15  \n",
       "1    -0.254157   2       22  \n",
       "2     1.693108   3       12  \n",
       "3     0.002062   4       15  \n",
       "4    -0.305401   5       22  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ef1a63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns = ['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8fa1059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "48334433",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainkeys.remove('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "36b7d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = train[trainkeys], train['credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "416f9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "62a1769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_checker\n",
    "def train_model(x_data, y_data, params, k=5, num_boost_round = 200, verbose_eval = 100, early_stopping_rounds = 100, stratified = False, return_models = False):\n",
    "    models = []\n",
    "    \n",
    "#     k_fold = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "    if stratified:\n",
    "        k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data, y_data]\n",
    "    else:\n",
    "        k_fold = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data]\n",
    "#     k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=123) if stratified else KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "    \n",
    "    \n",
    "    for train_idx, val_idx in k_fold.split(*data):\n",
    "        x_train, y_train = x_data.iloc[train_idx], y_data.iloc[train_idx]\n",
    "        x_val, y_val = x_data.iloc[val_idx], y_data.iloc[val_idx]\n",
    "    \n",
    "        d_train = xgb.DMatrix(data = x_train, label = y_train)\n",
    "        d_val = xgb.DMatrix(data = x_val, label = y_val)\n",
    "        \n",
    "        wlist = [(d_train, 'train'), (d_val, 'eval')]\n",
    "        \n",
    "        model = xgb.train(params=params, dtrain=d_train, num_boost_round = num_boost_round, evals=wlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose_eval)\n",
    "        models.append(model)\n",
    "    \n",
    "    print(f\"{k} fold mean score:\", np.mean([i.best_score for i in models]))\n",
    "    \n",
    "    if return_models:\n",
    "        return models\n",
    "\n",
    "@time_checker\n",
    "def last_train(X_test, y_test, params, num_boost_round = 200):\n",
    "    print(\"***최종 학습 전 하이퍼 파라미터 다시한번 확인!!***\")\n",
    "    \n",
    "    d_test = xgb.DMatrix(data = X_test, label = y_test)\n",
    "    model = xgb.train(params = params, dtrain = d_test, num_boost_round = num_boost_round)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_XGBparams(booster):\n",
    "    config = json.loads(booster.save_config()) # your xgb booster object\n",
    "    stack = [config]\n",
    "    internal = {}\n",
    "    while stack:\n",
    "        obj = stack.pop()\n",
    "        for k, v in obj.items():\n",
    "            if k.endswith('_param'):\n",
    "                for p_k, p_v in v.items():\n",
    "                    internal[p_k] = p_v\n",
    "            elif isinstance(v, dict):\n",
    "                stack.append(v)\n",
    "    return internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9ee99217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cat_model(x_data, y_data, cat_cols, x_test = None, k=5, \n",
    "                    num_boost_round = 200, verbose_eval = 100, \n",
    "                    early_stopping_rounds = 100, stratified = False, \n",
    "                    return_models = False, return_pred_data = False):\n",
    "    models = []\n",
    "    if return_pred_data:\n",
    "        assert type(x_test) != type(None), \"If return_pred_data is True, X_test data must be passed\"\n",
    "        oof_train = np.zeros([x_data.shape[0], len(np.unique(y_data))])\n",
    "        oof_test  = np.zeros([x_test.shape[0], len(np.unique(y_data))])\n",
    "    \n",
    "    if stratified:\n",
    "        k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data, y_data]\n",
    "    else:\n",
    "        k_fold = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data]\n",
    "\n",
    "\n",
    "\n",
    "    for train_idx, val_idx in k_fold.split(*data):\n",
    "        x_train, y_train = x_data.iloc[train_idx], y_data.iloc[train_idx]\n",
    "        x_val, y_val = x_data.iloc[val_idx], y_data.iloc[val_idx]\n",
    "\n",
    "        model = CatBoostClassifier()\n",
    "        train_data = Pool(data=x_train, label=y_train, cat_features=cat_cols)\n",
    "        valid_data = Pool(data=x_val, label=y_val, cat_features=cat_cols)\n",
    "        model.fit(train_data, \n",
    "                  eval_set=valid_data, \n",
    "                  use_best_model=True, \n",
    "                  early_stopping_rounds=100, \n",
    "                  verbose=100)\n",
    "        models.append(model)\n",
    "        \n",
    "        if return_pred_data:\n",
    "            oof_train[val_idx] += model.predict_proba(x_val)\n",
    "            oof_test           += model.predict_proba(x_test)/k\n",
    "        \n",
    "        \n",
    "    print(f\"{k} fold mean score:\", np.mean([i.best_score_['validation']['MultiClass'] for i in models]))\n",
    "    \n",
    "    if return_models:\n",
    "        return models\n",
    "    \n",
    "    if return_pred_data:\n",
    "        return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1f710c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type', 'ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31c6de6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0350538\ttest: 1.0338581\tbest: 1.0338581 (0)\ttotal: 171ms\tremaining: 2m 50s\n",
      "100:\tlearn: 0.7161785\ttest: 0.6776288\tbest: 0.6776288 (100)\ttotal: 2.58s\tremaining: 22.9s\n",
      "200:\tlearn: 0.6895159\ttest: 0.6752061\tbest: 0.6750262 (197)\ttotal: 5.17s\tremaining: 20.6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6750261896\n",
      "bestIteration = 197\n",
      "\n",
      "Shrink model to first 198 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0344780\ttest: 1.0349782\tbest: 1.0349782 (0)\ttotal: 22.7ms\tremaining: 22.7s\n",
      "100:\tlearn: 0.7125680\ttest: 0.6979928\tbest: 0.6979928 (100)\ttotal: 2.81s\tremaining: 25s\n",
      "200:\tlearn: 0.6864949\ttest: 0.6974120\tbest: 0.6966422 (147)\ttotal: 5.89s\tremaining: 23.4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6966422327\n",
      "bestIteration = 147\n",
      "\n",
      "Shrink model to first 148 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0344759\ttest: 1.0350522\tbest: 1.0350522 (0)\ttotal: 11.4ms\tremaining: 11.4s\n",
      "100:\tlearn: 0.7157616\ttest: 0.6933591\tbest: 0.6933591 (100)\ttotal: 2.56s\tremaining: 22.8s\n",
      "200:\tlearn: 0.6892748\ttest: 0.6926187\tbest: 0.6920586 (193)\ttotal: 5.2s\tremaining: 20.7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6920585856\n",
      "bestIteration = 193\n",
      "\n",
      "Shrink model to first 194 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0343632\ttest: 1.0351167\tbest: 1.0351167 (0)\ttotal: 11.6ms\tremaining: 11.6s\n",
      "100:\tlearn: 0.7156688\ttest: 0.6899798\tbest: 0.6899798 (100)\ttotal: 2.53s\tremaining: 22.5s\n",
      "200:\tlearn: 0.6869676\ttest: 0.6892701\tbest: 0.6882856 (150)\ttotal: 5.37s\tremaining: 21.3s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6882855545\n",
      "bestIteration = 150\n",
      "\n",
      "Shrink model to first 151 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0349541\ttest: 1.0341723\tbest: 1.0341723 (0)\ttotal: 11.1ms\tremaining: 11.1s\n",
      "100:\tlearn: 0.7144400\ttest: 0.6928744\tbest: 0.6928744 (100)\ttotal: 2.38s\tremaining: 21.2s\n",
      "200:\tlearn: 0.6879319\ttest: 0.6908079\tbest: 0.6908079 (200)\ttotal: 4.9s\tremaining: 19.5s\n",
      "300:\tlearn: 0.6657269\ttest: 0.6919838\tbest: 0.6905734 (202)\ttotal: 7.5s\tremaining: 17.4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6905733815\n",
      "bestIteration = 202\n",
      "\n",
      "Shrink model to first 203 iterations.\n",
      "5 fold mean score: 0.6885171887787549\n"
     ]
    }
   ],
   "source": [
    "models = train_cat_model(X_train, y_train, \n",
    "                         cat_cols, \n",
    "                         return_models = True, \n",
    "                         stratified = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6de3fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CatBoostClassifier()\n",
    "train_data = Pool(data=X_train, label=y_train, cat_features=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b93b361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.092454\n",
      "0:\tlearn: 1.0467848\ttotal: 18.7ms\tremaining: 18.7s\n",
      "100:\tlearn: 0.7128433\ttotal: 2.47s\tremaining: 22s\n",
      "200:\tlearn: 0.6933421\ttotal: 5.25s\tremaining: 20.9s\n",
      "300:\tlearn: 0.6769266\ttotal: 8.32s\tremaining: 19.3s\n",
      "400:\tlearn: 0.6608961\ttotal: 11.2s\tremaining: 16.8s\n",
      "500:\tlearn: 0.6446641\ttotal: 14.2s\tremaining: 14.1s\n",
      "600:\tlearn: 0.6281730\ttotal: 17.2s\tremaining: 11.4s\n",
      "700:\tlearn: 0.6124723\ttotal: 20.3s\tremaining: 8.64s\n",
      "800:\tlearn: 0.5973685\ttotal: 23.3s\tremaining: 5.8s\n",
      "900:\tlearn: 0.5836272\ttotal: 26.4s\tremaining: 2.9s\n",
      "999:\tlearn: 0.5678838\ttotal: 29.5s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x17af16e4e88>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.fit(train_data, early_stopping_rounds=100, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed608dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e47a9d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0339501\ttest: 1.0359612\tbest: 1.0359612 (0)\ttotal: 26.8ms\tremaining: 26.8s\n",
      "100:\tlearn: 0.7102960\ttest: 0.7124339\tbest: 0.7122634 (98)\ttotal: 2.46s\tremaining: 21.9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7122634453\n",
      "bestIteration = 98\n",
      "\n",
      "Shrink model to first 99 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0351155\ttest: 1.0338431\tbest: 1.0338431 (0)\ttotal: 14.2ms\tremaining: 14.2s\n",
      "100:\tlearn: 0.7144005\ttest: 0.6869832\tbest: 0.6869832 (100)\ttotal: 2.48s\tremaining: 22.1s\n",
      "200:\tlearn: 0.6874009\ttest: 0.6860406\tbest: 0.6859865 (151)\ttotal: 5.47s\tremaining: 21.8s\n",
      "300:\tlearn: 0.6631787\ttest: 0.6862291\tbest: 0.6854076 (278)\ttotal: 8.12s\tremaining: 18.8s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6854075845\n",
      "bestIteration = 278\n",
      "\n",
      "Shrink model to first 279 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0349601\ttest: 1.0340840\tbest: 1.0340840 (0)\ttotal: 17ms\tremaining: 17s\n",
      "100:\tlearn: 0.7176280\ttest: 0.6848068\tbest: 0.6848068 (100)\ttotal: 2.48s\tremaining: 22.1s\n",
      "200:\tlearn: 0.6895313\ttest: 0.6831578\tbest: 0.6830137 (182)\ttotal: 5.14s\tremaining: 20.4s\n",
      "300:\tlearn: 0.6666374\ttest: 0.6829723\tbest: 0.6825856 (278)\ttotal: 7.78s\tremaining: 18.1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6825855789\n",
      "bestIteration = 278\n",
      "\n",
      "Shrink model to first 279 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0350745\ttest: 1.0338797\tbest: 1.0338797 (0)\ttotal: 11.7ms\tremaining: 11.7s\n",
      "100:\tlearn: 0.7181289\ttest: 0.6851899\tbest: 0.6851782 (98)\ttotal: 2.45s\tremaining: 21.8s\n",
      "200:\tlearn: 0.6916011\ttest: 0.6845972\tbest: 0.6843610 (132)\ttotal: 5.19s\tremaining: 20.6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6843610328\n",
      "bestIteration = 132\n",
      "\n",
      "Shrink model to first 133 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0342091\ttest: 1.0354272\tbest: 1.0354272 (0)\ttotal: 11.8ms\tremaining: 11.8s\n",
      "100:\tlearn: 0.7076790\ttest: 0.7105758\tbest: 0.7105758 (100)\ttotal: 2.52s\tremaining: 22.4s\n",
      "200:\tlearn: 0.6818435\ttest: 0.7106546\tbest: 0.7094341 (138)\ttotal: 5.27s\tremaining: 20.9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7094340993\n",
      "bestIteration = 138\n",
      "\n",
      "Shrink model to first 139 iterations.\n",
      "5 fold mean score: 0.6948103481657721\n"
     ]
    }
   ],
   "source": [
    "oof_train, oof_test = \\\n",
    "train_cat_model(X_train, \n",
    "                y_train,\n",
    "                cat_cols, \n",
    "                X_test,\n",
    "                return_pred_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4e36cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21160, 3), (5291, 3))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train.shape, oof_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a92eecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6948103481657713"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_train, oof_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d69c8f0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6947316289825596"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, oof_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d716b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467bebee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25704a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d1914a8",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9490f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF_model(x_data, y_data, params, x_test = None, k=5, \n",
    "                    num_boost_round = 200, verbose_eval = 100, \n",
    "                    early_stopping_rounds = 100, stratified = False, \n",
    "                    return_models = False, return_pred_data = False):\n",
    "    models = []\n",
    "    if return_pred_data:\n",
    "        assert type(x_test) != type(None), \"If return_pred_data is True, X_test data must be passed\"\n",
    "        oof_train = np.zeros([x_data.shape[0], len(np.unique(y_data))])\n",
    "        oof_test  = np.zeros([x_test.shape[0], len(np.unique(y_data))])\n",
    "    \n",
    "    if stratified:\n",
    "        k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data, y_data]\n",
    "    else:\n",
    "        k_fold = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data]\n",
    "    \n",
    "\n",
    "\n",
    "    for train_idx, val_idx in k_fold.split(*data):\n",
    "        x_train, y_train = x_data.iloc[train_idx], y_data.iloc[train_idx]\n",
    "        x_val, y_val = x_data.iloc[val_idx], y_data.iloc[val_idx]\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators      = params['n_estimators'],\n",
    "                                       max_depth         = params['max_depth'],\n",
    "                                       criterion         = params['criterion'],\n",
    "                                       min_samples_leaf  = params['min_samples_leaf'],\n",
    "                                       min_samples_split = params['min_samples_split'],\n",
    "                                       n_jobs            = 4)\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        models.append(model)\n",
    "        \n",
    "        print(f\"{k} Fold log loss:\", log_loss(y_val, model.predict_proba(x_val)))\n",
    "        \n",
    "        if return_pred_data:\n",
    "            oof_train[val_idx] += model.predict_proba(x_val)\n",
    "            oof_test           += model.predict_proba(x_test)/k\n",
    "        \n",
    "        \n",
    "#     print(f\"{k} fold mean score:\", np.mean([i.best_score_['validation']['MultiClass'] for i in models]))\n",
    "    \n",
    "    if return_models:\n",
    "        return models\n",
    "    \n",
    "    if return_pred_data:\n",
    "        return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "58bdca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\HwaLang\\Desktop\\python\\T academy\\Kaggle_camp\\credit_card_dacon\\NNI\\RF\\RF_params_0.704.json\") as f:\n",
    "    RF_params = json.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e180b1f1",
   "metadata": {},
   "source": [
    "with open(r\"C:\\Users\\HwaLang\\Desktop\\python\\T academy\\Kaggle_camp\\credit_card_dacon\\NNI\\RF\\model\\RF_model0.7194.pkl\", \"rb\") as f:\n",
    "    RF_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f966bbf9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 7271,\n",
       " 'max_depth': 35,\n",
       " 'criterion': 'entropy',\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_samples_split': 12,\n",
       " 'scaler': 'minmax'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_params"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a102f32",
   "metadata": {},
   "source": [
    "oof_train_RF, oof_test_RF = \\\n",
    "train_RF_model(X_train, \n",
    "               y_train,\n",
    "               RF_params, \n",
    "               X_test,\n",
    "               return_pred_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449af009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa42fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f2514d3",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7ed5418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_XGB_model(x_data, y_data, params, x_test = None, k=5, \n",
    "                    num_boost_round = 200, verbose_eval = 100, \n",
    "                    early_stopping_rounds = 100, stratified = False, \n",
    "                    return_models = False, return_pred_data = False):\n",
    "    models = []\n",
    "    if return_pred_data:\n",
    "        assert type(x_test) != type(None), \"If return_pred_data is True, X_test data must be passed\"\n",
    "        oof_train = np.zeros([x_data.shape[0], len(np.unique(y_data))])\n",
    "        oof_test  = np.zeros([x_test.shape[0], len(np.unique(y_data))])\n",
    "    \n",
    "    if stratified:\n",
    "        k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data, y_data]\n",
    "    else:\n",
    "        k_fold = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data]\n",
    "    \n",
    "    cv_scores = list()\n",
    "\n",
    "    for train_idx, val_idx in k_fold.split(*data):\n",
    "        x_train, y_train = x_data.iloc[train_idx], y_data.iloc[train_idx]\n",
    "        x_val, y_val = x_data.iloc[val_idx], y_data.iloc[val_idx]\n",
    "\n",
    "        model = XGBClassifier(n_estimators     = 1000000,\n",
    "                              subsample        = params['subsample'],\n",
    "                              max_depth        = params['max_depth'],\n",
    "                              colsample_bytree = params['colsample_bytree'],\n",
    "                              eta              = params['eta'],\n",
    "                              n_jobs           = 4)\n",
    "        \n",
    "        model.fit(x_train, y_train,\n",
    "                  eval_set=[[x_train, y_train], [x_val, y_val]],\n",
    "                  eval_metric='mlogloss',\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=100)\n",
    "        \n",
    "        models.append(model)\n",
    "        \n",
    "        if return_pred_data:\n",
    "            oof_train[val_idx] += model.predict_proba(x_val)\n",
    "            oof_test           += model.predict_proba(x_test)/k\n",
    "        \n",
    "        \n",
    "#     print(f\"{k} fold mean score:\", np.mean([i.best_score_['validation']['MultiClass'] for i in models]))\n",
    "    \n",
    "    if return_models:\n",
    "        return models\n",
    "    \n",
    "    if return_pred_data:\n",
    "        return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5490afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\HwaLang\\Desktop\\python\\T academy\\Kaggle_camp\\credit_card_dacon\\NNI\\XGB\\1st_sol_params_0.696406.json\") as f:\n",
    "    XGB_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b04a60c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.04068\tvalidation_1-mlogloss:1.05431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-mlogloss:0.21427\tvalidation_1-mlogloss:0.76280\n",
      "[150]\tvalidation_0-mlogloss:0.14149\tvalidation_1-mlogloss:0.81855\n",
      "[0]\tvalidation_0-mlogloss:1.04012\tvalidation_1-mlogloss:1.05245\n",
      "[100]\tvalidation_0-mlogloss:0.21568\tvalidation_1-mlogloss:0.73590\n",
      "[150]\tvalidation_0-mlogloss:0.14042\tvalidation_1-mlogloss:0.78780\n",
      "[0]\tvalidation_0-mlogloss:1.03877\tvalidation_1-mlogloss:1.05193\n",
      "[100]\tvalidation_0-mlogloss:0.21618\tvalidation_1-mlogloss:0.73934\n",
      "[144]\tvalidation_0-mlogloss:0.15068\tvalidation_1-mlogloss:0.78246\n",
      "[0]\tvalidation_0-mlogloss:1.03916\tvalidation_1-mlogloss:1.05371\n",
      "[100]\tvalidation_0-mlogloss:0.21538\tvalidation_1-mlogloss:0.72174\n",
      "[151]\tvalidation_0-mlogloss:0.14337\tvalidation_1-mlogloss:0.76898\n",
      "[0]\tvalidation_0-mlogloss:1.04098\tvalidation_1-mlogloss:1.05398\n",
      "[100]\tvalidation_0-mlogloss:0.21903\tvalidation_1-mlogloss:0.77573\n",
      "[142]\tvalidation_0-mlogloss:0.15243\tvalidation_1-mlogloss:0.82274\n"
     ]
    }
   ],
   "source": [
    "oof_train_XGB, oof_test_XGB = \\\n",
    "train_XGB_model(X_train, \n",
    "                y_train,\n",
    "                XGB_params, \n",
    "                X_test,\n",
    "                return_pred_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1289fd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7154997320541561"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_train, oof_train_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65848c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7136794378540435"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, oof_test_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c84629c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a1a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4cb0bbf",
   "metadata": {},
   "source": [
    "## lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b56921d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LGB_model(x_data, y_data, params, x_test = None, k=5, \n",
    "                    num_boost_round = 200, verbose_eval = 100, \n",
    "                    early_stopping_rounds = 100, stratified = False, \n",
    "                    return_models = False, return_pred_data = False):\n",
    "    models = []\n",
    "    if return_pred_data:\n",
    "        assert type(x_test) != type(None), \"If return_pred_data is True, X_test data must be passed\"\n",
    "        oof_train = np.zeros([x_data.shape[0], len(np.unique(y_data))])\n",
    "        oof_test  = np.zeros([x_test.shape[0], len(np.unique(y_data))])\n",
    "    \n",
    "    if stratified:\n",
    "        k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data, y_data]\n",
    "    else:\n",
    "        k_fold = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data]\n",
    "    \n",
    "    cv_scores = list()\n",
    "\n",
    "    for train_idx, val_idx in k_fold.split(*data):\n",
    "        x_train, y_train = x_data.iloc[train_idx], y_data.iloc[train_idx]\n",
    "        x_val, y_val = x_data.iloc[val_idx], y_data.iloc[val_idx]\n",
    "\n",
    "        model = LGBMClassifier(n_estimators     = 1000000,\n",
    "                               subsample        = params['subsample'],\n",
    "                               max_depth        = params['max_depth'],\n",
    "                               colsample_bytree = params['colsample_bytree'],\n",
    "                               learning_rate    = params['lr'],\n",
    "                               n_jobs           = 4)\n",
    "        \n",
    "        model.fit(x_train, y_train,\n",
    "                  eval_set=[[x_train, y_train], [x_val, y_val]],\n",
    "                  eval_metric='multi_logloss',\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=100)\n",
    "\n",
    "        \n",
    "        models.append(model)\n",
    "        \n",
    "        if return_pred_data:\n",
    "            oof_train[val_idx] += model.predict_proba(x_val)\n",
    "            oof_test           += model.predict_proba(x_test)/k\n",
    "        \n",
    "        \n",
    "#     print(f\"{k} fold mean score:\", np.mean([i.best_score_['validation']['MultiClass'] for i in models]))\n",
    "    \n",
    "    if return_models:\n",
    "        return models\n",
    "    \n",
    "    if return_pred_data:\n",
    "        return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cd14ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\HwaLang\\Desktop\\python\\T academy\\Kaggle_camp\\credit_card_dacon\\NNI\\LGBM\\LGBM_parmas_7107.json\") as f:\n",
    "    LGB_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c45b121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.587332\tvalid_1's multi_logloss: 0.756191\n",
      "[200]\ttraining's multi_logloss: 0.476508\tvalid_1's multi_logloss: 0.744994\n",
      "[300]\ttraining's multi_logloss: 0.39985\tvalid_1's multi_logloss: 0.743663\n",
      "Early stopping, best iteration is:\n",
      "[250]\ttraining's multi_logloss: 0.434875\tvalid_1's multi_logloss: 0.742413\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.594476\tvalid_1's multi_logloss: 0.732487\n",
      "[200]\ttraining's multi_logloss: 0.481488\tvalid_1's multi_logloss: 0.71885\n",
      "[300]\ttraining's multi_logloss: 0.403398\tvalid_1's multi_logloss: 0.717737\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttraining's multi_logloss: 0.451092\tvalid_1's multi_logloss: 0.716585\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.594421\tvalid_1's multi_logloss: 0.733862\n",
      "[200]\ttraining's multi_logloss: 0.484274\tvalid_1's multi_logloss: 0.720104\n",
      "[300]\ttraining's multi_logloss: 0.407907\tvalid_1's multi_logloss: 0.719042\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's multi_logloss: 0.438633\tvalid_1's multi_logloss: 0.717617\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.595294\tvalid_1's multi_logloss: 0.737514\n",
      "[200]\ttraining's multi_logloss: 0.486113\tvalid_1's multi_logloss: 0.722453\n",
      "[300]\ttraining's multi_logloss: 0.409461\tvalid_1's multi_logloss: 0.719893\n",
      "Early stopping, best iteration is:\n",
      "[260]\ttraining's multi_logloss: 0.437441\tvalid_1's multi_logloss: 0.719441\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.590474\tvalid_1's multi_logloss: 0.756633\n",
      "[200]\ttraining's multi_logloss: 0.478462\tvalid_1's multi_logloss: 0.747753\n",
      "[300]\ttraining's multi_logloss: 0.400818\tvalid_1's multi_logloss: 0.753575\n",
      "Early stopping, best iteration is:\n",
      "[211]\ttraining's multi_logloss: 0.46855\tvalid_1's multi_logloss: 0.746847\n"
     ]
    }
   ],
   "source": [
    "oof_train_LGB, oof_test_LGB = \\\n",
    "train_LGB_model(X_train, \n",
    "                y_train,\n",
    "                LGB_params, \n",
    "                X_test,\n",
    "                return_pred_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "998ded3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7285805737517002"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_train, oof_train_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2f19cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7282079180196158"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, oof_test_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "133c3ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = np.concatenate([oof_train, oof_train_LGB, oof_train_XGB], axis = 1)\n",
    "new_X_train = pd.DataFrame(new_X_train, index = X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b259b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test = np.concatenate([oof_test, oof_test_LGB, oof_test_XGB], axis = 1)\n",
    "new_X_test = pd.DataFrame(new_X_test, index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe5d453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "49445fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.02149\tvalidation_1-mlogloss:1.03851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-mlogloss:0.23147\tvalidation_1-mlogloss:0.75980\n",
      "[128]\tvalidation_0-mlogloss:0.19038\tvalidation_1-mlogloss:0.77364\n",
      "[0]\tvalidation_0-mlogloss:1.02326\tvalidation_1-mlogloss:1.03616\n",
      "[100]\tvalidation_0-mlogloss:0.23425\tvalidation_1-mlogloss:0.72719\n",
      "[129]\tvalidation_0-mlogloss:0.19270\tvalidation_1-mlogloss:0.74178\n",
      "[0]\tvalidation_0-mlogloss:1.02231\tvalidation_1-mlogloss:1.03653\n",
      "[100]\tvalidation_0-mlogloss:0.23481\tvalidation_1-mlogloss:0.72438\n",
      "[132]\tvalidation_0-mlogloss:0.19118\tvalidation_1-mlogloss:0.73832\n",
      "[0]\tvalidation_0-mlogloss:1.02149\tvalidation_1-mlogloss:1.03821\n",
      "[100]\tvalidation_0-mlogloss:0.23459\tvalidation_1-mlogloss:0.71995\n",
      "[133]\tvalidation_0-mlogloss:0.18644\tvalidation_1-mlogloss:0.73332\n",
      "[0]\tvalidation_0-mlogloss:1.02238\tvalidation_1-mlogloss:1.03840\n",
      "[100]\tvalidation_0-mlogloss:0.22836\tvalidation_1-mlogloss:0.75187\n",
      "[127]\tvalidation_0-mlogloss:0.18993\tvalidation_1-mlogloss:0.76495\n"
     ]
    }
   ],
   "source": [
    "models = train_XGB_model(new_X_train, y_train, XGB_params, return_models=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d11685fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7143310813056885\n",
      "0.7132537063218948\n",
      "0.7138759394791847\n",
      "0.7145480732196751\n",
      "0.709304477049957\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(log_loss(y_test, model.predict_proba(new_X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3569c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_X = pd.concat([new_X_train,new_X_test]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0092f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_y = pd.concat([y_train, y_test]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e9a026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05d846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb95b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ee334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc636c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9a48960a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.114773\n",
      "0:\tlearn: 1.0147814\ttest: 1.0125947\tbest: 1.0125947 (0)\ttotal: 4.7ms\tremaining: 4.7s\n",
      "100:\tlearn: 0.6747220\ttest: 0.6810895\tbest: 0.6809687 (86)\ttotal: 394ms\tremaining: 3.51s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6809687295\n",
      "bestIteration = 86\n",
      "\n",
      "Shrink model to first 87 iterations.\n",
      "Learning rate set to 0.114773\n",
      "0:\tlearn: 1.0126813\ttest: 1.0160999\tbest: 1.0160999 (0)\ttotal: 4.57ms\tremaining: 4.56s\n",
      "100:\tlearn: 0.6655921\ttest: 0.7131194\tbest: 0.7126164 (73)\ttotal: 407ms\tremaining: 3.62s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7126163636\n",
      "bestIteration = 73\n",
      "\n",
      "Shrink model to first 74 iterations.\n",
      "Learning rate set to 0.114773\n",
      "0:\tlearn: 1.0134394\ttest: 1.0134492\tbest: 1.0134492 (0)\ttotal: 4.42ms\tremaining: 4.41s\n",
      "100:\tlearn: 0.6700063\ttest: 0.6968974\tbest: 0.6963565 (43)\ttotal: 396ms\tremaining: 3.52s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6963564752\n",
      "bestIteration = 43\n",
      "\n",
      "Shrink model to first 44 iterations.\n",
      "Learning rate set to 0.114773\n",
      "0:\tlearn: 1.0137595\ttest: 1.0134815\tbest: 1.0134815 (0)\ttotal: 4.62ms\tremaining: 4.62s\n",
      "100:\tlearn: 0.6734399\ttest: 0.6839107\tbest: 0.6839107 (100)\ttotal: 396ms\tremaining: 3.53s\n",
      "200:\tlearn: 0.6521805\ttest: 0.6849210\tbest: 0.6837788 (105)\ttotal: 787ms\tremaining: 3.13s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6837787993\n",
      "bestIteration = 105\n",
      "\n",
      "Shrink model to first 106 iterations.\n",
      "Learning rate set to 0.114773\n",
      "0:\tlearn: 1.0144561\ttest: 1.0147979\tbest: 1.0147979 (0)\ttotal: 4.49ms\tremaining: 4.49s\n",
      "100:\tlearn: 0.6712274\ttest: 0.6956380\tbest: 0.6948874 (80)\ttotal: 410ms\tremaining: 3.65s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6948873516\n",
      "bestIteration = 80\n",
      "\n",
      "Shrink model to first 81 iterations.\n",
      "5 fold mean score: 0.6937215438474157\n"
     ]
    }
   ],
   "source": [
    "models = train_cat_model(stacked_X, stacked_y, cat_cols=None, return_models=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "69718a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6825198912930569\n",
      "0.6824337396315\n",
      "0.6884385662152506\n",
      "0.6792339737317\n",
      "0.6827488142110296\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(log_loss(y_test, model.predict_proba(new_X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b0a211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e68e0b71",
   "metadata": {},
   "source": [
    "stacked_X.to_csv(\"stacked_X.csv\", index = False)\n",
    "stacked_y.to_csv(\"stacked_y.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632981ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e9ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1e269947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0330658\ttest: 1.0356520\tbest: 1.0356520 (0)\ttotal: 11.4ms\tremaining: 11.4s\n",
      "100:\tlearn: 0.7085298\ttest: 0.7049034\tbest: 0.7048776 (98)\ttotal: 2.3s\tremaining: 20.5s\n",
      "200:\tlearn: 0.6804322\ttest: 0.7054955\tbest: 0.7043537 (131)\ttotal: 4.84s\tremaining: 19.2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7043537203\n",
      "bestIteration = 131\n",
      "\n",
      "Shrink model to first 132 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0337235\ttest: 1.0346017\tbest: 1.0346017 (0)\ttotal: 22.1ms\tremaining: 22.1s\n",
      "100:\tlearn: 0.7097573\ttest: 0.6973224\tbest: 0.6967707 (94)\ttotal: 2.29s\tremaining: 20.4s\n",
      "200:\tlearn: 0.6828045\ttest: 0.6962259\tbest: 0.6956834 (157)\ttotal: 4.7s\tremaining: 18.7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.695683397\n",
      "bestIteration = 157\n",
      "\n",
      "Shrink model to first 158 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0346992\ttest: 1.0327935\tbest: 1.0327935 (0)\ttotal: 19.3ms\tremaining: 19.3s\n",
      "100:\tlearn: 0.7172468\ttest: 0.6763257\tbest: 0.6761844 (98)\ttotal: 2.31s\tremaining: 20.5s\n",
      "200:\tlearn: 0.6905924\ttest: 0.6753606\tbest: 0.6746535 (160)\ttotal: 4.71s\tremaining: 18.7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6746535148\n",
      "bestIteration = 160\n",
      "\n",
      "Shrink model to first 161 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0348512\ttest: 1.0326104\tbest: 1.0326104 (0)\ttotal: 19.1ms\tremaining: 19s\n",
      "100:\tlearn: 0.7163398\ttest: 0.6818022\tbest: 0.6818022 (100)\ttotal: 2.27s\tremaining: 20.2s\n",
      "200:\tlearn: 0.6891347\ttest: 0.6808021\tbest: 0.6798682 (183)\ttotal: 4.71s\tremaining: 18.7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6798681568\n",
      "bestIteration = 183\n",
      "\n",
      "Shrink model to first 184 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0337685\ttest: 1.0343513\tbest: 1.0343513 (0)\ttotal: 18.4ms\tremaining: 18.3s\n",
      "100:\tlearn: 0.7122009\ttest: 0.6903249\tbest: 0.6902116 (97)\ttotal: 2.28s\tremaining: 20.3s\n",
      "200:\tlearn: 0.6845798\ttest: 0.6887794\tbest: 0.6885764 (141)\ttotal: 4.76s\tremaining: 18.9s\n",
      "300:\tlearn: 0.6620267\ttest: 0.6902752\tbest: 0.6884670 (216)\ttotal: 7.28s\tremaining: 16.9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.688467004\n",
      "bestIteration = 216\n",
      "\n",
      "Shrink model to first 217 iterations.\n",
      "5 fold mean score: 0.6886051585625357\n"
     ]
    }
   ],
   "source": [
    "cat_models = train_cat_model(X_train,\n",
    "                y_train,\n",
    "                cat_cols, \n",
    "                X_test,\n",
    "                return_models = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2fd15c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.583492\tvalid_1's multi_logloss: 0.756717\n",
      "[200]\ttraining's multi_logloss: 0.473812\tvalid_1's multi_logloss: 0.745684\n",
      "[300]\ttraining's multi_logloss: 0.397463\tvalid_1's multi_logloss: 0.746904\n",
      "Early stopping, best iteration is:\n",
      "[242]\ttraining's multi_logloss: 0.439385\tvalid_1's multi_logloss: 0.743947\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.588132\tvalid_1's multi_logloss: 0.742758\n",
      "[200]\ttraining's multi_logloss: 0.477986\tvalid_1's multi_logloss: 0.732046\n",
      "[300]\ttraining's multi_logloss: 0.401109\tvalid_1's multi_logloss: 0.732171\n",
      "Early stopping, best iteration is:\n",
      "[225]\ttraining's multi_logloss: 0.457331\tvalid_1's multi_logloss: 0.730536\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.595899\tvalid_1's multi_logloss: 0.734618\n",
      "[200]\ttraining's multi_logloss: 0.484215\tvalid_1's multi_logloss: 0.717275\n",
      "[300]\ttraining's multi_logloss: 0.407799\tvalid_1's multi_logloss: 0.713879\n",
      "Early stopping, best iteration is:\n",
      "[257]\ttraining's multi_logloss: 0.43739\tvalid_1's multi_logloss: 0.713501\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.593073\tvalid_1's multi_logloss: 0.734948\n",
      "[200]\ttraining's multi_logloss: 0.482902\tvalid_1's multi_logloss: 0.722074\n",
      "[300]\ttraining's multi_logloss: 0.404333\tvalid_1's multi_logloss: 0.720498\n",
      "Early stopping, best iteration is:\n",
      "[254]\ttraining's multi_logloss: 0.437593\tvalid_1's multi_logloss: 0.718759\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.591744\tvalid_1's multi_logloss: 0.744296\n",
      "[200]\ttraining's multi_logloss: 0.480754\tvalid_1's multi_logloss: 0.72918\n",
      "[300]\ttraining's multi_logloss: 0.402462\tvalid_1's multi_logloss: 0.722518\n",
      "[400]\ttraining's multi_logloss: 0.344\tvalid_1's multi_logloss: 0.727822\n",
      "Early stopping, best iteration is:\n",
      "[312]\ttraining's multi_logloss: 0.395083\tvalid_1's multi_logloss: 0.722323\n"
     ]
    }
   ],
   "source": [
    "LGB_models = train_LGB_model(X_train, \n",
    "                y_train,\n",
    "                LGB_params, \n",
    "                X_test,\n",
    "                return_models = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "823724f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.03734\tvalidation_1-mlogloss:1.05447\n",
      "[100]\tvalidation_0-mlogloss:0.21516\tvalidation_1-mlogloss:0.75752\n",
      "[149]\tvalidation_0-mlogloss:0.14296\tvalidation_1-mlogloss:0.81071\n",
      "[0]\tvalidation_0-mlogloss:1.03944\tvalidation_1-mlogloss:1.05292\n",
      "[100]\tvalidation_0-mlogloss:0.21287\tvalidation_1-mlogloss:0.75374\n",
      "[148]\tvalidation_0-mlogloss:0.14359\tvalidation_1-mlogloss:0.80524\n",
      "[0]\tvalidation_0-mlogloss:1.03922\tvalidation_1-mlogloss:1.05281\n",
      "[100]\tvalidation_0-mlogloss:0.22385\tvalidation_1-mlogloss:0.72381\n",
      "[152]\tvalidation_0-mlogloss:0.14457\tvalidation_1-mlogloss:0.77728\n",
      "[0]\tvalidation_0-mlogloss:1.03849\tvalidation_1-mlogloss:1.05218\n",
      "[100]\tvalidation_0-mlogloss:0.21510\tvalidation_1-mlogloss:0.73484\n",
      "[151]\tvalidation_0-mlogloss:0.14046\tvalidation_1-mlogloss:0.78851\n",
      "[0]\tvalidation_0-mlogloss:1.04015\tvalidation_1-mlogloss:1.05324\n",
      "[100]\tvalidation_0-mlogloss:0.21445\tvalidation_1-mlogloss:0.73531\n",
      "[152]\tvalidation_0-mlogloss:0.14001\tvalidation_1-mlogloss:0.78708\n"
     ]
    }
   ],
   "source": [
    "XGB_models = train_XGB_model(X_train, \n",
    "                y_train,\n",
    "                XGB_params, \n",
    "                X_test,\n",
    "                return_models = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_models, XGB_models, LGB_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e3ceea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f401e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_test = np.zeros([test.shape[0], 3])\n",
    "for cm in cat_models:\n",
    "    cat_test += cm.predict_proba(test)/len(cat_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5c062173",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_test = np.zeros([test.shape[0], 3])\n",
    "for cm in XGB_models:\n",
    "    XGB_test += cm.predict_proba(test)/len(XGB_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "32c277f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_test = np.zeros([test.shape[0], 3])\n",
    "for cm in LGB_models:\n",
    "    LGB_test += cm.predict_proba(test)/len(LGB_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "defc4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob = np.concatenate([cat_test, XGB_test, LGB_test], axis = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ca48f76",
   "metadata": {},
   "source": [
    "pd.DataFrame(test_prob).to_csv(\"test_ensem.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1203ce04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec96e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc7682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
