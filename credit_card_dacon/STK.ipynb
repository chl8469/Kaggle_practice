{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e7705171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, PowerTransformer, StandardScaler, \\\n",
    "                                    MinMaxScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, log_loss, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from function_dt_check import time_checker\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "import json\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68870059",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.family'] = 'Hancom Gothic'\n",
    "plt.style.use('bmh')\n",
    "plt.rc('font',size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed6feb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/HwaLang/Desktop/python/T academy/Kaggle_camp/'\n",
    "train_path = os.path.join(BASE_DIR, 'data', 'MDC14', 'train.csv')\n",
    "test_path  = os.path.join(BASE_DIR, 'data', 'MDC14', 'test.csv')\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "submission = pd.read_csv(f'{BASE_DIR}/data/MDC14/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec6f3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna('NaN', inplace=True) \n",
    "test.fillna('NaN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15ca0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train['family_size'] <= 7)]\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27a347f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['FLAG_MOBIL'], axis=1, inplace=True)\n",
    "test.drop(['FLAG_MOBIL'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "869e2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['DAYS_EMPLOYED'] = train['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "test['DAYS_EMPLOYED'] = test['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a8b0e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['DAYS_BIRTH', 'begin_month', 'DAYS_EMPLOYED']\n",
    "for feat in feats:\n",
    "    train[feat]=np.abs(train[feat])\n",
    "    test[feat]=np.abs(test[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd4bd094",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    # before_EMPLOYED: 고용되기 전까지의 일수\n",
    "    df['before_EMPLOYED'] = df['DAYS_BIRTH'] - df['DAYS_EMPLOYED']\n",
    "    df['income_total_befofeEMP_ratio'] = df['income_total'] / df['before_EMPLOYED']\n",
    "    df['before_EMPLOYED_m'] = np.floor(df['before_EMPLOYED'] / 30) - ((np.floor(df['before_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "    df['before_EMPLOYED_w'] = np.floor(df['before_EMPLOYED'] / 7) - ((np.floor(df['before_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "    \n",
    "    #DAYS_BIRTH 파생변수- Age(나이), 태어난 월, 태어난 주(출생연도의 n주차)\n",
    "    df['Age'] = df['DAYS_BIRTH'] // 365\n",
    "    df['DAYS_BIRTH_m'] = np.floor(df['DAYS_BIRTH'] / 30) - ((np.floor(df['DAYS_BIRTH'] / 30) / 12).astype(int) * 12)\n",
    "    df['DAYS_BIRTH_w'] = np.floor(df['DAYS_BIRTH'] / 7) - ((np.floor(df['DAYS_BIRTH'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "    \n",
    "    #DAYS_EMPLOYED_m 파생변수- EMPLOYED(근속연수), DAYS_EMPLOYED_m(고용된 달) ,DAYS_EMPLOYED_w(고용된 주(고용연도의 n주차))  \n",
    "    df['EMPLOYED'] = df['DAYS_EMPLOYED'] // 365\n",
    "    df['DAYS_EMPLOYED_m'] = np.floor(df['DAYS_EMPLOYED'] / 30) - ((np.floor(df['DAYS_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "    df['DAYS_EMPLOYED_w'] = np.floor(df['DAYS_EMPLOYED'] / 7) - ((np.floor(df['DAYS_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "    #ability: 소득/(살아온 일수+ 근무일수)\n",
    "    df['ability'] = df['income_total'] / (df['DAYS_BIRTH'] + df['DAYS_EMPLOYED'])\n",
    "    \n",
    "    #income_mean: 소득/ 가족 수\n",
    "    df['income_mean'] = df['income_total'] / df['family_size']\n",
    "    \n",
    "    #ID 생성: 각 컬럼의 값들을 더해서 고유한 사람을 파악(*한 사람이 여러 개 카드를 만들 가능성을 고려해 begin_month는 제외함)\n",
    "    df['ID'] = \\\n",
    "    df['child_num'].astype(str) + '_' + df['income_total'].astype(str) + '_' +\\\n",
    "    df['DAYS_BIRTH'].astype(str) + '_' + df['DAYS_EMPLOYED'].astype(str) + '_' +\\\n",
    "    df['work_phone'].astype(str) + '_' + df['phone'].astype(str) + '_' +\\\n",
    "    df['email'].astype(str) + '_' + df['family_size'].astype(str) + '_' +\\\n",
    "    df['gender'].astype(str) + '_' + df['car'].astype(str) + '_' +\\\n",
    "    df['reality'].astype(str) + '_' + df['income_type'].astype(str) + '_' +\\\n",
    "    df['edu_type'].astype(str) + '_' + df['family_type'].astype(str) + '_' +\\\n",
    "    df['house_type'].astype(str) + '_' + df['occyp_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55231c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED',]\n",
    "train.drop(cols, axis=1, inplace=True)\n",
    "test.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d770dc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Numerical features:  19\n",
      "Number of Categorical features:  9\n"
     ]
    }
   ],
   "source": [
    "numerical_feats = train.dtypes[train.dtypes != \"object\"].index.tolist()\n",
    "numerical_feats.remove('credit')\n",
    "print(\"Number of Numerical features: \", len(numerical_feats))\n",
    "\n",
    "categorical_feats = train.dtypes[train.dtypes == \"object\"].index.tolist()\n",
    "print(\"Number of Categorical features: \", len(categorical_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abcd1512",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    df['income_total'] = np.log1p(1+df['income_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f2072cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder(categorical_feats)\n",
    "train[categorical_feats] = encoder.fit_transform(train[categorical_feats], train['credit'])\n",
    "test[categorical_feats] = encoder.transform(test[categorical_feats])\n",
    "\n",
    "train['ID'] = train['ID'].astype('int64')\n",
    "test['ID'] = test['ID'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "998e423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_train = train.drop(['credit'], axis=1)\n",
    "kmeans = KMeans(n_clusters=36, random_state=42).fit(kmeans_train)\n",
    "train['cluster'] = kmeans.predict(kmeans_train)\n",
    "test['cluster'] = kmeans.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64876878",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feats.remove('income_total')\n",
    "scaler = StandardScaler()\n",
    "train[numerical_feats] = scaler.fit_transform(train[numerical_feats])\n",
    "test[numerical_feats] = scaler.transform(test[numerical_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd3ea96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainkeys = train.keys().to_list()\n",
    "trainkeys.remove('credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbef2229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>DAYS_BIRTH_m</th>\n",
       "      <th>DAYS_BIRTH_w</th>\n",
       "      <th>EMPLOYED</th>\n",
       "      <th>DAYS_EMPLOYED_m</th>\n",
       "      <th>DAYS_EMPLOYED_w</th>\n",
       "      <th>ability</th>\n",
       "      <th>income_mean</th>\n",
       "      <th>ID</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.731942</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.218505</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452826</td>\n",
       "      <td>0.442795</td>\n",
       "      <td>-0.443485</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>-1.230046</td>\n",
       "      <td>-1.077087</td>\n",
       "      <td>-0.032496</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.731811</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.419174</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.060773</td>\n",
       "      <td>0.442795</td>\n",
       "      <td>-0.443485</td>\n",
       "      <td>-0.250471</td>\n",
       "      <td>-0.424295</td>\n",
       "      <td>-1.077087</td>\n",
       "      <td>1.190137</td>\n",
       "      <td>-0.254157</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.731680</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13.017007</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763069</td>\n",
       "      <td>-1.582567</td>\n",
       "      <td>0.451504</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>-0.424295</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>1.186515</td>\n",
       "      <td>1.693108</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.731549</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.218505</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192277</td>\n",
       "      <td>1.310808</td>\n",
       "      <td>1.346494</td>\n",
       "      <td>-0.094880</td>\n",
       "      <td>1.187206</td>\n",
       "      <td>0.629874</td>\n",
       "      <td>0.101168</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.731418</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11.967193</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192277</td>\n",
       "      <td>1.021471</td>\n",
       "      <td>-1.338475</td>\n",
       "      <td>-0.094880</td>\n",
       "      <td>1.455790</td>\n",
       "      <td>-1.077087</td>\n",
       "      <td>-0.282885</td>\n",
       "      <td>-0.305401</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  gender  car  reality  income_total  income_type  edu_type  \\\n",
       "0 -1.731942       1    1        1     12.218505            1         1   \n",
       "1 -1.731811       1    1        2     12.419174            1         2   \n",
       "2 -1.731680       2    2        2     13.017007            2         1   \n",
       "3 -1.731549       1    1        2     12.218505            1         2   \n",
       "4 -1.731418       1    2        2     11.967193            3         1   \n",
       "\n",
       "   family_type  house_type  work_phone  ...       Age  DAYS_BIRTH_m  \\\n",
       "0            1           1   -0.538321  ... -0.452826      0.442795   \n",
       "1            2           2   -0.538321  ... -1.060773      0.442795   \n",
       "2            1           2   -0.538321  ...  0.763069     -1.582567   \n",
       "3            1           2   -0.538321  ... -0.192277      1.310808   \n",
       "4            1           2   -0.538321  ... -0.192277      1.021471   \n",
       "\n",
       "   DAYS_BIRTH_w  EMPLOYED  DAYS_EMPLOYED_m  DAYS_EMPLOYED_w   ability  \\\n",
       "0     -0.443485  0.994253        -1.230046        -1.077087 -0.032496   \n",
       "1     -0.443485 -0.250471        -0.424295        -1.077087  1.190137   \n",
       "2      0.451504  0.994253        -0.424295        -0.223607  1.186515   \n",
       "3      1.346494 -0.094880         1.187206         0.629874  0.101168   \n",
       "4     -1.338475 -0.094880         1.455790        -1.077087 -0.282885   \n",
       "\n",
       "   income_mean  ID  cluster  \n",
       "0     0.002062   1       15  \n",
       "1    -0.254157   2       22  \n",
       "2     1.693108   3       12  \n",
       "3     0.002062   4       15  \n",
       "4    -0.305401   5       22  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "2d873cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns = ['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "76d7a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainkeys.remove('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "36b7d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = train[trainkeys], train['credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "f386d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "62a1769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_checker\n",
    "def train_model(x_data, y_data, params, k=5, num_boost_round = 200, verbose_eval = 100, early_stopping_rounds = 100, stratified = False, return_models = False):\n",
    "    models = []\n",
    "    \n",
    "#     k_fold = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "    if stratified:\n",
    "        k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data, y_data]\n",
    "    else:\n",
    "        k_fold = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data]\n",
    "#     k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=123) if stratified else KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "    \n",
    "    \n",
    "    for train_idx, val_idx in k_fold.split(*data):\n",
    "        x_train, y_train = x_data.iloc[train_idx], y_data.iloc[train_idx]\n",
    "        x_val, y_val = x_data.iloc[val_idx], y_data.iloc[val_idx]\n",
    "    \n",
    "        d_train = xgb.DMatrix(data = x_train, label = y_train)\n",
    "        d_val = xgb.DMatrix(data = x_val, label = y_val)\n",
    "        \n",
    "        wlist = [(d_train, 'train'), (d_val, 'eval')]\n",
    "        \n",
    "        model = xgb.train(params=params, dtrain=d_train, num_boost_round = num_boost_round, evals=wlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose_eval)\n",
    "        models.append(model)\n",
    "    \n",
    "    print(f\"{k} fold mean score:\", np.mean([i.best_score for i in models]))\n",
    "    \n",
    "    if return_models:\n",
    "        return models\n",
    "\n",
    "@time_checker\n",
    "def last_train(X_test, y_test, params, num_boost_round = 200):\n",
    "    print(\"***최종 학습 전 하이퍼 파라미터 다시한번 확인!!***\")\n",
    "    \n",
    "    d_test = xgb.DMatrix(data = X_test, label = y_test)\n",
    "    model = xgb.train(params = params, dtrain = d_test, num_boost_round = num_boost_round)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_XGBparams(booster):\n",
    "    config = json.loads(booster.save_config()) # your xgb booster object\n",
    "    stack = [config]\n",
    "    internal = {}\n",
    "    while stack:\n",
    "        obj = stack.pop()\n",
    "        for k, v in obj.items():\n",
    "            if k.endswith('_param'):\n",
    "                for p_k, p_v in v.items():\n",
    "                    internal[p_k] = p_v\n",
    "            elif isinstance(v, dict):\n",
    "                stack.append(v)\n",
    "    return internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9ee99217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cat_model(x_data, y_data, cat_cols, x_test = None, k=5, \n",
    "                    num_boost_round = 200, verbose_eval = 100, \n",
    "                    early_stopping_rounds = 100, stratified = False, \n",
    "                    return_models = False, return_pred_data = False):\n",
    "    models = []\n",
    "    if return_pred_data:\n",
    "        assert type(x_test) != type(None), \"If return_pred_data is True, X_test data must be passed\"\n",
    "        oof_train = np.zeros([x_data.shape[0], len(np.unique(y_data))])\n",
    "        oof_test  = np.zeros([x_test.shape[0], len(np.unique(y_data))])\n",
    "    \n",
    "    if stratified:\n",
    "        k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data, y_data]\n",
    "    else:\n",
    "        k_fold = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data]\n",
    "\n",
    "\n",
    "\n",
    "    for train_idx, val_idx in k_fold.split(*data):\n",
    "        x_train, y_train = x_data.iloc[train_idx], y_data.iloc[train_idx]\n",
    "        x_val, y_val = x_data.iloc[val_idx], y_data.iloc[val_idx]\n",
    "\n",
    "        model = CatBoostClassifier()\n",
    "        train_data = Pool(data=x_train, label=y_train, cat_features=cat_cols)\n",
    "        valid_data = Pool(data=x_val, label=y_val, cat_features=cat_cols)\n",
    "        model.fit(train_data, \n",
    "                  eval_set=valid_data, \n",
    "                  use_best_model=True, \n",
    "                  early_stopping_rounds=100, \n",
    "                  verbose=100)\n",
    "        models.append(model)\n",
    "        \n",
    "        if return_pred_data:\n",
    "            oof_train[val_idx] += model.predict_proba(x_val)\n",
    "            oof_test           += model.predict_proba(x_test)/k\n",
    "        \n",
    "        \n",
    "    print(f\"{k} fold mean score:\", np.mean([i.best_score_['validation']['MultiClass'] for i in models]))\n",
    "    \n",
    "    if return_models:\n",
    "        return models\n",
    "    \n",
    "    if return_pred_data:\n",
    "        return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "1f710c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type', 'ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6de6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = train_cat_model(X_train, y_train, \n",
    "                         cat_cols, \n",
    "                         return_models = True, \n",
    "                         stratified = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6de3fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CatBoostClassifier()\n",
    "train_data = Pool(data=X_train, label=y_train, cat_features=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b93b361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.093512\n",
      "0:\tlearn: 1.0460853\ttotal: 35ms\tremaining: 35s\n",
      "100:\tlearn: 0.7049386\ttotal: 2.75s\tremaining: 24.4s\n",
      "200:\tlearn: 0.6888987\ttotal: 5.69s\tremaining: 22.6s\n",
      "300:\tlearn: 0.6740002\ttotal: 8.72s\tremaining: 20.3s\n",
      "400:\tlearn: 0.6604176\ttotal: 11.9s\tremaining: 17.7s\n",
      "500:\tlearn: 0.6456102\ttotal: 14.9s\tremaining: 14.9s\n",
      "600:\tlearn: 0.6314189\ttotal: 18s\tremaining: 12s\n",
      "700:\tlearn: 0.6177031\ttotal: 21.1s\tremaining: 9.01s\n",
      "800:\tlearn: 0.6038913\ttotal: 24.2s\tremaining: 6.01s\n",
      "900:\tlearn: 0.5896405\ttotal: 27.2s\tremaining: 2.99s\n",
      "999:\tlearn: 0.5775733\ttotal: 30.3s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x21910a8e6c8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.fit(train_data, early_stopping_rounds=100, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b628cbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "9542bc70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0345192\ttest: 1.0319239\tbest: 1.0319239 (0)\ttotal: 115ms\tremaining: 1m 54s\n",
      "100:\tlearn: 0.7172598\ttest: 0.6745758\tbest: 0.6745758 (100)\ttotal: 16.5s\tremaining: 2m 27s\n",
      "200:\tlearn: 0.6915700\ttest: 0.6730706\tbest: 0.6729763 (191)\ttotal: 33.8s\tremaining: 2m 14s\n",
      "300:\tlearn: 0.6675533\ttest: 0.6723003\tbest: 0.6722588 (298)\ttotal: 51.7s\tremaining: 2m\n",
      "400:\tlearn: 0.6432754\ttest: 0.6732031\tbest: 0.6722277 (316)\ttotal: 1m 10s\tremaining: 1m 45s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6722276719\n",
      "bestIteration = 316\n",
      "\n",
      "Shrink model to first 317 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0333498\ttest: 1.0340394\tbest: 1.0340394 (0)\ttotal: 106ms\tremaining: 1m 45s\n",
      "100:\tlearn: 0.7093765\ttest: 0.6999286\tbest: 0.6999286 (100)\ttotal: 16.6s\tremaining: 2m 27s\n",
      "200:\tlearn: 0.6822070\ttest: 0.6983957\tbest: 0.6981992 (168)\ttotal: 32.9s\tremaining: 2m 10s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6981991587\n",
      "bestIteration = 168\n",
      "\n",
      "Shrink model to first 169 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0330857\ttest: 1.0344802\tbest: 1.0344802 (0)\ttotal: 165ms\tremaining: 2m 44s\n",
      "100:\tlearn: 0.7142428\ttest: 0.6927174\tbest: 0.6927174 (100)\ttotal: 16.5s\tremaining: 2m 26s\n",
      "200:\tlearn: 0.6887768\ttest: 0.6903495\tbest: 0.6899625 (188)\ttotal: 33.9s\tremaining: 2m 14s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.689962472\n",
      "bestIteration = 188\n",
      "\n",
      "Shrink model to first 189 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0333719\ttest: 1.0340147\tbest: 1.0340147 (0)\ttotal: 197ms\tremaining: 3m 16s\n",
      "100:\tlearn: 0.7123364\ttest: 0.6928332\tbest: 0.6927289 (98)\ttotal: 18.3s\tremaining: 2m 42s\n",
      "200:\tlearn: 0.6858669\ttest: 0.6921032\tbest: 0.6916228 (142)\ttotal: 36.9s\tremaining: 2m 26s\n",
      "300:\tlearn: 0.6629459\ttest: 0.6924756\tbest: 0.6916141 (230)\ttotal: 53.5s\tremaining: 2m 4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6916141001\n",
      "bestIteration = 230\n",
      "\n",
      "Shrink model to first 231 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0337019\ttest: 1.0335150\tbest: 1.0335150 (0)\ttotal: 135ms\tremaining: 2m 14s\n",
      "100:\tlearn: 0.7119841\ttest: 0.6815515\tbest: 0.6814908 (99)\ttotal: 15.9s\tremaining: 2m 21s\n",
      "200:\tlearn: 0.6835895\ttest: 0.6801011\tbest: 0.6795797 (155)\ttotal: 33.2s\tremaining: 2m 11s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6795797467\n",
      "bestIteration = 155\n",
      "\n",
      "Shrink model to first 156 iterations.\n",
      "5 fold mean score: 0.6863166298941773\n"
     ]
    }
   ],
   "source": [
    "oof_train, oof_test = \\\n",
    "train_cat_model(X_train, \n",
    "                y_train,\n",
    "                cat_cols, \n",
    "                X_test,\n",
    "                return_pred_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "34cace0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21160, 3), (5291, 3))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train.shape, oof_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9e113191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.686316629894177"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_train, oof_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "3846850f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.703847516022256"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, oof_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565cf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a6063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af2805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0e2ec09",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d7ce5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF_model(x_data, y_data, params, x_test = None, k=5, \n",
    "                    num_boost_round = 200, verbose_eval = 100, \n",
    "                    early_stopping_rounds = 100, stratified = False, \n",
    "                    return_models = False, return_pred_data = False):\n",
    "    models = []\n",
    "    if return_pred_data:\n",
    "        assert type(x_test) != type(None), \"If return_pred_data is True, X_test data must be passed\"\n",
    "        oof_train = np.zeros([x_data.shape[0], len(np.unique(y_data))])\n",
    "        oof_test  = np.zeros([x_test.shape[0], len(np.unique(y_data))])\n",
    "    \n",
    "    if stratified:\n",
    "        k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data, y_data]\n",
    "    else:\n",
    "        k_fold = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data]\n",
    "    \n",
    "\n",
    "\n",
    "    for train_idx, val_idx in k_fold.split(*data):\n",
    "        x_train, y_train = x_data.iloc[train_idx], y_data.iloc[train_idx]\n",
    "        x_val, y_val = x_data.iloc[val_idx], y_data.iloc[val_idx]\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators      = params['n_estimators'],\n",
    "                                       max_depth         = params['max_depth'],\n",
    "                                       criterion         = params['criterion'],\n",
    "                                       min_samples_leaf  = params['min_samples_leaf'],\n",
    "                                       min_samples_split = params['min_samples_split'],\n",
    "                                       n_jobs            = 4)\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        models.append(model)\n",
    "        \n",
    "        print(f\"{k} Fold log loss:\", log_loss(y_val, model.predict_proba(x_val)))\n",
    "        \n",
    "        if return_pred_data:\n",
    "            oof_train[val_idx] += model.predict_proba(x_val)\n",
    "            oof_test           += model.predict_proba(x_test)/k\n",
    "        \n",
    "        \n",
    "#     print(f\"{k} fold mean score:\", np.mean([i.best_score_['validation']['MultiClass'] for i in models]))\n",
    "    \n",
    "    if return_models:\n",
    "        return models\n",
    "    \n",
    "    if return_pred_data:\n",
    "        return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4498c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\HwaLang\\Desktop\\python\\T academy\\Kaggle_camp\\credit_card_dacon\\NNI\\RF\\RF_params_0.704.json\") as f:\n",
    "    RF_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "daedd4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\HwaLang\\Desktop\\python\\T academy\\Kaggle_camp\\credit_card_dacon\\NNI\\RF\\model\\RF_model0.7194.pkl\", \"rb\") as f:\n",
    "    RF_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f966bbf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 7271,\n",
       " 'max_depth': 35,\n",
       " 'criterion': 'entropy',\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_samples_split': 12,\n",
       " 'scaler': 'minmax'}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4cbe3cad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Fold log loss: 0.742402665476749\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-252-ad674408f356>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                \u001b[0mRF_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                return_pred_data = True)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-249-6ebccf0b4907>\u001b[0m in \u001b[0;36mtrain_RF_model\u001b[1;34m(x_data, y_data, params, x_test, k, num_boost_round, verbose_eval, early_stopping_rounds, stratified, return_models, return_pred_data)\u001b[0m\n\u001b[0;32m     29\u001b[0m                                        n_jobs            = 4)\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    391\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 393\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hltorch\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hltorch\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hltorch\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hltorch\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hltorch\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hltorch\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "oof_train_RF, oof_test_RF = \\\n",
    "train_RF_model(X_train, \n",
    "               y_train,\n",
    "               RF_params, \n",
    "               X_test,\n",
    "               return_pred_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a1bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f61be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6730b80",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_XGB_model(x_data, y_data, params, x_test = None, k=5, \n",
    "                    num_boost_round = 200, verbose_eval = 100, \n",
    "                    early_stopping_rounds = 100, stratified = False, \n",
    "                    return_models = False, return_pred_data = False):\n",
    "    models = []\n",
    "    if return_pred_data:\n",
    "        assert type(x_test) != type(None), \"If return_pred_data is True, X_test data must be passed\"\n",
    "        oof_train = np.zeros([x_data.shape[0], len(np.unique(y_data))])\n",
    "        oof_test  = np.zeros([x_test.shape[0], len(np.unique(y_data))])\n",
    "    \n",
    "    if stratified:\n",
    "        k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data, y_data]\n",
    "    else:\n",
    "        k_fold = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        data = [x_data]\n",
    "    \n",
    "    cv_scores = list()\n",
    "\n",
    "    for train_idx, val_idx in k_fold.split(*data):\n",
    "        x_train, y_train = x_data.iloc[train_idx], y_data.iloc[train_idx]\n",
    "        x_val, y_val = x_data.iloc[val_idx], y_data.iloc[val_idx]\n",
    "\n",
    "        model = XGBClassifier(n_estimators     = 1000000,\n",
    "                              subsample        = params['subsample'],\n",
    "                              max_depth        = params['max_depth'],\n",
    "                              colsample_bytree = params['colsample_bytree'],\n",
    "                              eta              = params['eta'],\n",
    "                              n_jobs           = 4)\n",
    "        \n",
    "        model.fit(x_train, y_train,\n",
    "                  eval_set=[[x_train, y_train], [x_valid, y_valid]],\n",
    "                  eval_metric='mlogloss',\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=100)\n",
    "        \n",
    "        models.append(model)\n",
    "        \n",
    "        if return_pred_data:\n",
    "            oof_train[val_idx] += model.predict_proba(x_val)\n",
    "            oof_test           += model.predict_proba(x_test)/k\n",
    "        \n",
    "        \n",
    "#     print(f\"{k} fold mean score:\", np.mean([i.best_score_['validation']['MultiClass'] for i in models]))\n",
    "    \n",
    "    if return_models:\n",
    "        return models\n",
    "    \n",
    "    if return_pred_data:\n",
    "        return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02890885",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\HwaLang\\Desktop\\python\\T academy\\Kaggle_camp\\credit_card_dacon\\NNI\\XGB\\1st_sol_params_0.696406.json\") as f:\n",
    "    XGB_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_train_XGB, oof_test_XGB = \\\n",
    "train_XGB_model(X_train, \n",
    "                y_train,\n",
    "                XGB_params, \n",
    "                X_test,\n",
    "                return_pred_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4a1745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0d478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9975228e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980c07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98234c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e93d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec96e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc7682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
