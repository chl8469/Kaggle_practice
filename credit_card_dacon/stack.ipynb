{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b7ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, PowerTransformer\n",
    "from sklearn.metrics import log_loss\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "import glob\n",
    "import pickle\n",
    "import multiprocessing\n",
    "n_cpus = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4defa198",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/HwaLang/Desktop/python/T academy/Kaggle_camp/'\n",
    "\n",
    "scaler_dict = {\n",
    "    \"minmax\": MinMaxScaler,\n",
    "    \"standard\": StandardScaler   \n",
    "}\n",
    "\n",
    "def select_scaler(name):\n",
    "    print(f\"Select {name} Scaler\")\n",
    "    \n",
    "    return scaler_dict[name]()\n",
    "\n",
    "def preprocess(x_train, x_valid, x_test, target):\n",
    "    # global num_columns, cat_columns\n",
    "\n",
    "    tmp_x_train = x_train.copy()\n",
    "    tmp_x_valid = x_valid.copy()    \n",
    "    tmp_x_test  = x_test.copy()\n",
    "# ---------------------------\n",
    "    tmp_x_train.drop(columns = ['FLAG_MOBIL'], inplace = True)\n",
    "    tmp_x_valid.drop(columns = ['FLAG_MOBIL'], inplace = True)\n",
    "    tmp_x_test.drop(columns = ['FLAG_MOBIL'], inplace = True)\n",
    "\n",
    "    tmp_x_train['DAYS_EMPLOYED'] = tmp_x_train['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "    tmp_x_valid['DAYS_EMPLOYED'] = tmp_x_valid['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "    tmp_x_test['DAYS_EMPLOYED'] = tmp_x_test['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "\n",
    "    feats = ['DAYS_BIRTH', 'begin_month', 'DAYS_EMPLOYED']\n",
    "    for feat in feats:\n",
    "        tmp_x_train[feat]=np.abs(tmp_x_train[feat])\n",
    "        tmp_x_valid[feat]=np.abs(tmp_x_valid[feat])\n",
    "        tmp_x_test[feat]=np.abs(tmp_x_test[feat])\n",
    "    \n",
    "    for df in [tmp_x_train, tmp_x_valid, tmp_x_test]:\n",
    "        # before_EMPLOYED: 고용되기 전까지의 일수\n",
    "        df['before_EMPLOYED'] = df['DAYS_BIRTH'] - df['DAYS_EMPLOYED']\n",
    "        df['income_total_befofeEMP_ratio'] = df['income_total'] / df['before_EMPLOYED']\n",
    "        df['before_EMPLOYED_m'] = np.floor(df['before_EMPLOYED'] / 30) - ((np.floor(df['before_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "        df['before_EMPLOYED_w'] = np.floor(df['before_EMPLOYED'] / 7) - ((np.floor(df['before_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "        \n",
    "        #DAYS_BIRTH 파생변수- Age(나이), 태어난 월, 태어난 주(출생연도의 n주차)\n",
    "        df['Age'] = df['DAYS_BIRTH'] // 365\n",
    "        df['DAYS_BIRTH_m'] = np.floor(df['DAYS_BIRTH'] / 30) - ((np.floor(df['DAYS_BIRTH'] / 30) / 12).astype(int) * 12)\n",
    "        df['DAYS_BIRTH_w'] = np.floor(df['DAYS_BIRTH'] / 7) - ((np.floor(df['DAYS_BIRTH'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "        \n",
    "        #DAYS_EMPLOYED_m 파생변수- EMPLOYED(근속연수), DAYS_EMPLOYED_m(고용된 달) ,DAYS_EMPLOYED_w(고용된 주(고용연도의 n주차))  \n",
    "        df['EMPLOYED'] = df['DAYS_EMPLOYED'] // 365\n",
    "        df['DAYS_EMPLOYED_m'] = np.floor(df['DAYS_EMPLOYED'] / 30) - ((np.floor(df['DAYS_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "        df['DAYS_EMPLOYED_w'] = np.floor(df['DAYS_EMPLOYED'] / 7) - ((np.floor(df['DAYS_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "        #ability: 소득/(살아온 일수+ 근무일수)\n",
    "        df['ability'] = df['income_total'] / (df['DAYS_BIRTH'] + df['DAYS_EMPLOYED'])\n",
    "        \n",
    "        #income_mean: 소득/ 가족 수\n",
    "        df['income_mean'] = df['income_total'] / df['family_size']\n",
    "        \n",
    "        #ID 생성: 각 컬럼의 값들을 더해서 고유한 사람을 파악(*한 사람이 여러 개 카드를 만들 가능성을 고려해 begin_month는 제외함)\n",
    "        df['ID'] = \\\n",
    "        df['child_num'].astype(str) + '_' + df['income_total'].astype(str) + '_' +\\\n",
    "        df['DAYS_BIRTH'].astype(str) + '_' + df['DAYS_EMPLOYED'].astype(str) + '_' +\\\n",
    "        df['work_phone'].astype(str) + '_' + df['phone'].astype(str) + '_' +\\\n",
    "        df['email'].astype(str) + '_' + df['family_size'].astype(str) + '_' +\\\n",
    "        df['gender'].astype(str) + '_' + df['car'].astype(str) + '_' +\\\n",
    "        df['reality'].astype(str) + '_' + df['income_type'].astype(str) + '_' +\\\n",
    "        df['edu_type'].astype(str) + '_' + df['family_type'].astype(str) + '_' +\\\n",
    "        df['house_type'].astype(str) + '_' + df['occyp_type'].astype(str)\n",
    "\n",
    "    cols = ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED',]\n",
    "    tmp_x_train.drop(cols, axis=1, inplace=True)\n",
    "    tmp_x_valid.drop(cols, axis=1, inplace=True)\n",
    "    tmp_x_test.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "    cat_columns = [c for (c, t) in zip(tmp_x_train.dtypes.index, tmp_x_train.dtypes) if t == 'O'] \n",
    "    num_columns = [c for c in tmp_x_train.columns if c not in cat_columns]\n",
    "\n",
    "    YJ_transform = PowerTransformer(method='yeo-johnson')\n",
    "    tmp_x_train['income_total'] = YJ_transform.fit_transform(tmp_x_train['income_total'].values.reshape(-1, 1))\n",
    "    tmp_x_valid['income_total'] = YJ_transform.transform(tmp_x_valid['income_total'].values.reshape(-1, 1))\n",
    "    tmp_x_test['income_total'] = YJ_transform.transform(tmp_x_test['income_total'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "    tmp_x_train.reset_index(drop=True, inplace=True)\n",
    "    tmp_x_valid.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    num_columns.remove(\"income_total\")\n",
    "\n",
    "    scaler = select_scaler(\"standard\")\n",
    "    tmp_x_train[num_columns] = scaler.fit_transform(tmp_x_train[num_columns])\n",
    "    tmp_x_valid[num_columns] = scaler.transform(tmp_x_valid[num_columns])\n",
    "    tmp_x_test[num_columns]  = scaler.transform(tmp_x_test[num_columns])\n",
    "\n",
    "    ode = OrdinalEncoder(cat_columns)\n",
    "    tmp_x_train[cat_columns] = ode.fit_transform(tmp_x_train[cat_columns], target)\n",
    "    tmp_x_valid[cat_columns] = ode.transform(tmp_x_valid[cat_columns])\n",
    "    tmp_x_test[cat_columns]  = ode.transform(tmp_x_test[cat_columns])\n",
    "\n",
    "    tmp_x_train['ID'] = tmp_x_train['ID'].astype('int64')\n",
    "    tmp_x_valid['ID'] = tmp_x_valid['ID'].astype('int64')\n",
    "    tmp_x_test['ID'] = tmp_x_test['ID'].astype('int64')\n",
    "\n",
    "# ---------------------------    \n",
    "    return tmp_x_train, tmp_x_valid, tmp_x_test, cat_columns, num_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fc76e81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21165, 18) (5292, 18)\n",
      "Select standard Scaler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3237: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(BASE_DIR, 'data', 'MDC14', 'train.csv')\n",
    "test_path  = os.path.join(BASE_DIR, 'data', 'MDC14', 'test.csv')\n",
    "\n",
    "data = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "data.fillna(\"NaN\", inplace = True)\n",
    "test.fillna(\"NaN\", inplace = True)\n",
    "\n",
    "label = data['credit'] \n",
    "\n",
    "data.drop(columns=['index', 'credit'], inplace=True)\n",
    "test.drop(columns=['index'], inplace=True) \n",
    "\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(label)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, label, test_size=0.2)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "X_train, X_test, test, cat_cols, num_cols = preprocess(X_train, X_test, test, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2f6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e1adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d8a44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_train = np.zeros((5, X_train.shape[0], 3))\n",
    "oof_test  = np.zeros((5, X_test.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d217f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\HwaLang\\Desktop\\python\\T academy\\Kaggle_camp\\credit_card_dacon\\NNI\\catboost\\model\\cat_model0.6756.pkl\", \"rb\") as f:\n",
    "    cat_model = pickle.load(f)\n",
    "params = cat_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9881933a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0369531\ttest: 1.0367023\tbest: 1.0367023 (0)\ttotal: 31.5ms\tremaining: 31.4s\n",
      "100:\tlearn: 0.7225396\ttest: 0.6937173\tbest: 0.6937173 (100)\ttotal: 2.08s\tremaining: 18.5s\n",
      "200:\tlearn: 0.6944234\ttest: 0.6914847\tbest: 0.6913701 (198)\ttotal: 4.35s\tremaining: 17.3s\n",
      "300:\tlearn: 0.6708604\ttest: 0.6925205\tbest: 0.6911628 (227)\ttotal: 6.67s\tremaining: 15.5s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.691162758\n",
      "bestIteration = 227\n",
      "\n",
      "Shrink model to first 228 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0370417\ttest: 1.0365240\tbest: 1.0365240 (0)\ttotal: 20.3ms\tremaining: 20.3s\n",
      "100:\tlearn: 0.7235900\ttest: 0.6991136\tbest: 0.6990485 (98)\ttotal: 2.09s\tremaining: 18.6s\n",
      "200:\tlearn: 0.6978491\ttest: 0.6978453\tbest: 0.6978063 (196)\ttotal: 4.36s\tremaining: 17.3s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6978063178\n",
      "bestIteration = 196\n",
      "\n",
      "Shrink model to first 197 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0367703\ttest: 1.0369906\tbest: 1.0369906 (0)\ttotal: 21.5ms\tremaining: 21.5s\n",
      "100:\tlearn: 0.7228883\ttest: 0.7074457\tbest: 0.7072235 (89)\ttotal: 2.03s\tremaining: 18.1s\n",
      "200:\tlearn: 0.6963923\ttest: 0.7058918\tbest: 0.7052799 (165)\ttotal: 4.26s\tremaining: 16.9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7052799354\n",
      "bestIteration = 165\n",
      "\n",
      "Shrink model to first 166 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0367287\ttest: 1.0370048\tbest: 1.0370048 (0)\ttotal: 23.2ms\tremaining: 23.1s\n",
      "100:\tlearn: 0.7254061\ttest: 0.7044142\tbest: 0.7044142 (100)\ttotal: 2.16s\tremaining: 19.3s\n",
      "200:\tlearn: 0.6985050\ttest: 0.7033340\tbest: 0.7029935 (172)\ttotal: 4.43s\tremaining: 17.6s\n",
      "300:\tlearn: 0.6739459\ttest: 0.7035351\tbest: 0.7025848 (277)\ttotal: 6.71s\tremaining: 15.6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7025848028\n",
      "bestIteration = 277\n",
      "\n",
      "Shrink model to first 278 iterations.\n",
      "Learning rate set to 0.114262\n",
      "0:\tlearn: 1.0368419\ttest: 1.0368024\tbest: 1.0368024 (0)\ttotal: 30.1ms\tremaining: 30.1s\n",
      "100:\tlearn: 0.7222676\ttest: 0.7091793\tbest: 0.7089649 (96)\ttotal: 2.09s\tremaining: 18.6s\n",
      "200:\tlearn: 0.6965755\ttest: 0.7080906\tbest: 0.7079142 (160)\ttotal: 4.4s\tremaining: 17.5s\n",
      "300:\tlearn: 0.6718072\ttest: 0.7084427\tbest: 0.7076704 (236)\ttotal: 6.7s\tremaining: 15.6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7076703892\n",
      "bestIteration = 236\n",
      "\n",
      "Shrink model to first 237 iterations.\n"
     ]
    }
   ],
   "source": [
    "# 예측하려는 유형에 따라 KFold or StratifiedKFold 선택\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, valid_index in skf.split(X_train, Y_train):\n",
    "    x_train, y_train = X_train.iloc[train_index, :], Y_train[train_index]\n",
    "    x_valid, y_valid = X_train.iloc[valid_index, :], Y_train[valid_index]\n",
    "\n",
    "#     x_train, x_valid, x_test = preprocess(x_train, x_valid, test, y_train)\n",
    "\n",
    "    model = CatBoostClassifier()\n",
    "\n",
    "    cat_cols = ['income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type', 'ID']\n",
    "\n",
    "    train_data = Pool(data=x_train, label=y_train, cat_features=cat_cols)\n",
    "    valid_data = Pool(data=x_valid, label=y_valid, cat_features=cat_cols)\n",
    "\n",
    "    model.fit(train_data, eval_set=valid_data, \n",
    "              use_best_model=True, \n",
    "              early_stopping_rounds=100, \n",
    "              verbose=100)\n",
    "\n",
    "    oof_train[0, valid_index,] += model.predict_proba(x_valid)\n",
    "    oof_test[0, :,]        += model.predict_proba(X_test) / n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4f9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db045a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c54e554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5786e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd74d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd9bd05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092876b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29f03d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84122028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed545490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41131bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a88bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fcc3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7807a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b7bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab25907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e8f683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3a2af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b5c7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
