{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ae55f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, PowerTransformer\n",
    "from sklearn.metrics import log_loss\n",
    "from category_encoders.ordinal import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "36004895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from os import remove as remove_file\n",
    "import glob\n",
    "import pickle\n",
    "import multiprocessing\n",
    "\n",
    "n_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "import nni\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, PowerTransformer\n",
    "from sklearn.metrics import log_loss\n",
    "from lightgbm import LGBMClassifier\n",
    "from category_encoders.ordinal import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a091a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/HwaLang/Desktop/python/T academy/Kaggle_camp/'\n",
    "\n",
    "scaler_dict = {\n",
    "    \"minmax\": MinMaxScaler,\n",
    "    \"standard\": StandardScaler   \n",
    "}\n",
    "\n",
    "def select_scaler(name):\n",
    "    print(f\"Select {name} Scaler\")\n",
    "    \n",
    "    return scaler_dict[name]()\n",
    "\n",
    "def preprocess(x_train, x_valid, x_test, target):\n",
    "    # global num_columns, cat_columns\n",
    "\n",
    "    tmp_x_train = x_train.copy()\n",
    "    tmp_x_valid = x_valid.copy()    \n",
    "    tmp_x_test  = x_test.copy()\n",
    "# ---------------------------\n",
    "    tmp_x_train.drop(columns = ['FLAG_MOBIL'], inplace = True)\n",
    "    tmp_x_valid.drop(columns = ['FLAG_MOBIL'], inplace = True)\n",
    "    tmp_x_test.drop(columns = ['FLAG_MOBIL'], inplace = True)\n",
    "\n",
    "    tmp_x_train['DAYS_EMPLOYED'] = tmp_x_train['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "    tmp_x_valid['DAYS_EMPLOYED'] = tmp_x_valid['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "    tmp_x_test['DAYS_EMPLOYED'] = tmp_x_test['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "\n",
    "    feats = ['DAYS_BIRTH', 'begin_month', 'DAYS_EMPLOYED']\n",
    "    for feat in feats:\n",
    "        tmp_x_train[feat]=np.abs(tmp_x_train[feat])\n",
    "        tmp_x_valid[feat]=np.abs(tmp_x_valid[feat])\n",
    "        tmp_x_test[feat]=np.abs(tmp_x_test[feat])\n",
    "    \n",
    "    for df in [tmp_x_train, tmp_x_valid, tmp_x_test]:\n",
    "        # before_EMPLOYED: 고용되기 전까지의 일수\n",
    "        df['before_EMPLOYED'] = df['DAYS_BIRTH'] - df['DAYS_EMPLOYED']\n",
    "        df['income_total_befofeEMP_ratio'] = df['income_total'] / df['before_EMPLOYED']\n",
    "        df['before_EMPLOYED_m'] = np.floor(df['before_EMPLOYED'] / 30) - ((np.floor(df['before_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "        df['before_EMPLOYED_w'] = np.floor(df['before_EMPLOYED'] / 7) - ((np.floor(df['before_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "        \n",
    "        #DAYS_BIRTH 파생변수- Age(나이), 태어난 월, 태어난 주(출생연도의 n주차)\n",
    "        df['Age'] = df['DAYS_BIRTH'] // 365\n",
    "        df['DAYS_BIRTH_m'] = np.floor(df['DAYS_BIRTH'] / 30) - ((np.floor(df['DAYS_BIRTH'] / 30) / 12).astype(int) * 12)\n",
    "        df['DAYS_BIRTH_w'] = np.floor(df['DAYS_BIRTH'] / 7) - ((np.floor(df['DAYS_BIRTH'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "        \n",
    "        #DAYS_EMPLOYED_m 파생변수- EMPLOYED(근속연수), DAYS_EMPLOYED_m(고용된 달) ,DAYS_EMPLOYED_w(고용된 주(고용연도의 n주차))  \n",
    "        df['EMPLOYED'] = df['DAYS_EMPLOYED'] // 365\n",
    "        df['DAYS_EMPLOYED_m'] = np.floor(df['DAYS_EMPLOYED'] / 30) - ((np.floor(df['DAYS_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "        df['DAYS_EMPLOYED_w'] = np.floor(df['DAYS_EMPLOYED'] / 7) - ((np.floor(df['DAYS_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "        #ability: 소득/(살아온 일수+ 근무일수)\n",
    "        df['ability'] = df['income_total'] / (df['DAYS_BIRTH'] + df['DAYS_EMPLOYED'])\n",
    "        \n",
    "        #income_mean: 소득/ 가족 수\n",
    "        df['income_mean'] = df['income_total'] / df['family_size']\n",
    "        \n",
    "        #ID 생성: 각 컬럼의 값들을 더해서 고유한 사람을 파악(*한 사람이 여러 개 카드를 만들 가능성을 고려해 begin_month는 제외함)\n",
    "        df['ID'] = \\\n",
    "        df['child_num'].astype(str) + '_' + df['income_total'].astype(str) + '_' +\\\n",
    "        df['DAYS_BIRTH'].astype(str) + '_' + df['DAYS_EMPLOYED'].astype(str) + '_' +\\\n",
    "        df['work_phone'].astype(str) + '_' + df['phone'].astype(str) + '_' +\\\n",
    "        df['email'].astype(str) + '_' + df['family_size'].astype(str) + '_' +\\\n",
    "        df['gender'].astype(str) + '_' + df['car'].astype(str) + '_' +\\\n",
    "        df['reality'].astype(str) + '_' + df['income_type'].astype(str) + '_' +\\\n",
    "        df['edu_type'].astype(str) + '_' + df['family_type'].astype(str) + '_' +\\\n",
    "        df['house_type'].astype(str) + '_' + df['occyp_type'].astype(str)\n",
    "\n",
    "    cols = ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED',]\n",
    "    tmp_x_train.drop(cols, axis=1, inplace=True)\n",
    "    tmp_x_valid.drop(cols, axis=1, inplace=True)\n",
    "    tmp_x_test.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "    cat_columns = [c for (c, t) in zip(tmp_x_train.dtypes.index, tmp_x_train.dtypes) if t == 'O'] \n",
    "    num_columns = [c for c in tmp_x_train.columns if c not in cat_columns]\n",
    "\n",
    "    YJ_transform = PowerTransformer(method='yeo-johnson')\n",
    "    tmp_x_train['income_total'] = YJ_transform.fit_transform(tmp_x_train['income_total'].values.reshape(-1, 1))\n",
    "    tmp_x_valid['income_total'] = YJ_transform.transform(tmp_x_valid['income_total'].values.reshape(-1, 1))\n",
    "    tmp_x_test['income_total'] = YJ_transform.transform(tmp_x_test['income_total'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "    tmp_x_train.reset_index(drop=True, inplace=True)\n",
    "    tmp_x_valid.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    num_columns.remove(\"income_total\")\n",
    "\n",
    "    scaler = select_scaler(\"standard\")\n",
    "    tmp_x_train[num_columns] = scaler.fit_transform(tmp_x_train[num_columns])\n",
    "    tmp_x_valid[num_columns] = scaler.transform(tmp_x_valid[num_columns])\n",
    "    tmp_x_test[num_columns]  = scaler.transform(tmp_x_test[num_columns])\n",
    "\n",
    "    ode = OrdinalEncoder(cat_columns)\n",
    "    tmp_x_train[cat_columns] = ode.fit_transform(tmp_x_train[cat_columns], target)\n",
    "    tmp_x_valid[cat_columns] = ode.transform(tmp_x_valid[cat_columns])\n",
    "    tmp_x_test[cat_columns]  = ode.transform(tmp_x_test[cat_columns])\n",
    "\n",
    "    tmp_x_train['ID'] = tmp_x_train['ID'].astype('int64')\n",
    "    tmp_x_valid['ID'] = tmp_x_valid['ID'].astype('int64')\n",
    "    tmp_x_test['ID'] = tmp_x_test['ID'].astype('int64')\n",
    "\n",
    "# ---------------------------    \n",
    "    return tmp_x_train, tmp_x_valid, tmp_x_test, cat_columns, num_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f2b0b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(BASE_DIR, 'data', 'MDC14', 'train.csv')\n",
    "test_path  = os.path.join(BASE_DIR, 'data', 'MDC14', 'test.csv')\n",
    "\n",
    "data = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "data.fillna(\"NaN\", inplace = True)\n",
    "test.fillna(\"NaN\", inplace = True)\n",
    "\n",
    "label = data['credit'] \n",
    "\n",
    "data.drop(columns=['index', 'credit'], inplace=True)\n",
    "test.drop(columns=['index'], inplace=True) \n",
    "\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(label)\n",
    "\n",
    "y_test_pred = np.zeros((test.shape[0], le.classes_.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "da52bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(data, label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d40f684a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21165, 18), (5292, 18))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8841d9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3237: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select standard Scaler\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, test, cat_cols, num_cols = preprocess(X_train, X_valid, test, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1d1e3ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26457, 18), (26457,))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b55182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d087ed0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21160</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21161</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21162</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21163</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21164</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21165 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  car  reality  income_type  edu_type  family_type  house_type  \\\n",
       "0           1    1        1            1         1            1           1   \n",
       "1           2    2        1            2         1            2           1   \n",
       "2           2    2        1            3         1            3           1   \n",
       "3           2    1        2            1         1            4           1   \n",
       "4           1    2        1            1         1            2           1   \n",
       "...       ...  ...      ...          ...       ...          ...         ...   \n",
       "21160       2    1        1            3         1            1           1   \n",
       "21161       2    1        2            1         1            1           1   \n",
       "21162       2    2        2            4         1            1           1   \n",
       "21163       2    1        2            2         1            1           1   \n",
       "21164       2    2        1            4         1            1           1   \n",
       "\n",
       "       occyp_type    ID  \n",
       "0               1     1  \n",
       "1               2     2  \n",
       "2               3     3  \n",
       "3               4     4  \n",
       "4               5     5  \n",
       "...           ...   ...  \n",
       "21160           2  5626  \n",
       "21161           1  4978  \n",
       "21162           6  4906  \n",
       "21163           7    24  \n",
       "21164           6  2535  \n",
       "\n",
       "[21165 rows x 9 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5f01b0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] 2\n",
      "[1 2] 2\n",
      "[1 2] 2\n",
      "[1 2 3 4 5] 5\n",
      "[1 2 3 4 5] 5\n",
      "[1 2 3 4 5] 5\n",
      "[1 2 3 4 5 6] 6\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] 19\n",
      "[   1    2    3 ... 7982 7983 7984] 7984\n"
     ]
    }
   ],
   "source": [
    "for cat in cat_cols:\n",
    "    print(np.unique(X_train[cat]), len(np.unique(X_train[cat])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b8afe84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] 2\n",
      "[1 2] 2\n",
      "[1 2] 2\n",
      "[1 2 3 4 5] 5\n",
      "[1 2 3 4 5] 5\n",
      "[1 2 3 4 5] 5\n",
      "[1 2 3 4 5 6] 6\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] 19\n",
      "[  -1    1    3 ... 8083 8086 8088] 3052\n"
     ]
    }
   ],
   "source": [
    "for cat in cat_cols:\n",
    "    print(np.unique(X_valid[cat]), len(np.unique(X_valid[cat])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "472538fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] 2\n",
      "[1 2] 2\n",
      "[1 2] 2\n",
      "[1 2 3 4 5] 5\n",
      "[1 2 3 4 5] 5\n",
      "[1 2 3 4 5] 5\n",
      "[1 2 3 4 5 6] 6\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] 19\n",
      "[  -1    2    3 ... 8086 8088 8089] 4423\n"
     ]
    }
   ],
   "source": [
    "for cat in cat_cols:\n",
    "    print(np.unique(test[cat]), len(np.unique(test[cat])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9914e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols.remove(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "219f65d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols.append(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c8c96eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_indics = [X_train.columns.get_loc(_) for _ in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abcf3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dims = [len(np.unique(X_train[_])) for _ in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "36c140d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "model = TabNetClassifier(\n",
    "    n_d=64, n_a=64, n_steps=5,\n",
    "    gamma=1.5, n_independent=2, n_shared=2,\n",
    "#     cat_idxs=cat_indics,\n",
    "#     cat_dims=cat_dims,\n",
    "#     cat_emb_dim=np.full(8, 3),\n",
    "    lambda_sparse=1e-3, momentum=0.3, clip_value=2.,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=1e-2),\n",
    "    scheduler_params = {\"gamma\": 0.95,\n",
    "                     \"step_size\": 20},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c1a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3b9df834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 5, 5, 5, 6, 19]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6ee5b7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'car', 'reality', 'income_total', 'income_type', 'edu_type',\n",
       "       'family_type', 'house_type', 'work_phone', 'phone', 'email',\n",
       "       'occyp_type', 'family_size', 'begin_month', 'before_EMPLOYED',\n",
       "       'income_total_befofeEMP_ratio', 'before_EMPLOYED_m',\n",
       "       'before_EMPLOYED_w', 'Age', 'DAYS_BIRTH_m', 'DAYS_BIRTH_w', 'EMPLOYED',\n",
       "       'DAYS_EMPLOYED_m', 'DAYS_EMPLOYED_w', 'ability', 'income_mean', 'ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66969c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5a3d781b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "You need the same number of rows between X_train (21165) and y_train (16932)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-208-5422cf2e83a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m           \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0meval_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m           max_epochs=100, patience=10)\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\hltorch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;31m# Validate and reformat eval set depending on training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_eval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         train_dataloader, valid_dataloaders = self._construct_loaders(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hltorch\\lib\\site-packages\\pytorch_tabnet\\utils.py\u001b[0m in \u001b[0;36mvalidate_eval_set\u001b[1;34m(eval_set, eval_name, X_train, y_train)\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;33m+\u001b[0m \u001b[1;34mf\"({X.shape[0]}) and y_{name} ({y.shape[0]})\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         )\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: You need the same number of rows between X_train (21165) and y_train (16932)"
     ]
    }
   ],
   "source": [
    "model.fit(X_train=X_train.values, y_train=y_train,\n",
    "          eval_set=[(X_train.values, y_train), (X_valid.values, y_valid)],\n",
    "          eval_name=['train', 'valid'],\n",
    "          max_epochs=100, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d8cf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960385ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98df68d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\HwaLang\\Desktop\\python\\T academy\\Kaggle_camp\\credit_card_dacon\\NNI\\SVM\\model\\SVM_model0.8828.pkl\", \"rb\") as f:\n",
    "    SVM = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "928c8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\HwaLang\\Desktop\\python\\T academy\\Kaggle_camp\\credit_card_dacon\\NNI\\catboost\\model\\cat_model0.6756.pkl\", \"rb\") as f:\n",
    "    cat_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2394363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\HwaLang\\Desktop\\python\\T academy\\Kaggle_camp\\credit_card_dacon\\NNI\\RF\\model\\RF_model0.7149.pkl\", \"rb\") as f:\n",
    "    RF_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4601b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\HwaLang\\Desktop\\python\\T academy\\Kaggle_camp\\credit_card_dacon\\NNI\\LGBM\\LGBM_parmas_7107.json\") as f:\n",
    "    LGB_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0764d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\HwaLang\\Desktop\\python\\T academy\\Kaggle_camp\\credit_card_dacon\\NNI\\XGB\\1st_sol_params_0.696406.json\") as f:\n",
    "    XGB_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3d2a498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 17,\n",
       " 'subsample': 0.922673956606362,\n",
       " 'colsample_bytree': 0.5207419913680738,\n",
       " 'lr': 0.1036444950112919,\n",
       " 'scaler': 'standard'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e05e5845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 13,\n",
       " 'subsample': 0.7391142820439047,\n",
       " 'colsample_bytree': 0.5021343602405989,\n",
       " 'eta': 0.10767423370018543,\n",
       " 'scaler': 'minmax'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21e54e29",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 32,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 29,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 3486,\n",
       " 'n_jobs': 4,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29cf8e42",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2.4301716177485737,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'sigmoid',\n",
       " 'max_iter': -1,\n",
       " 'probability': True,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 3.010968297611586e-05,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "34b699b9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.11053624353417138,\n",
       " 'depth': 5,\n",
       " 'border_count': 207,\n",
       " 'bagging_temperature': 1,\n",
       " 'min_data_in_leaf': 5}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d114e59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f401b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "77befcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21165, 18) (5292, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3237: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select standard Scaler\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(BASE_DIR, 'data', 'MDC14', 'train.csv')\n",
    "test_path  = os.path.join(BASE_DIR, 'data', 'MDC14', 'test.csv')\n",
    "\n",
    "data = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "data.fillna(\"NaN\", inplace = True)\n",
    "test.fillna(\"NaN\", inplace = True)\n",
    "\n",
    "label = data['credit'] \n",
    "\n",
    "data.drop(columns=['index', 'credit'], inplace=True)\n",
    "test.drop(columns=['index'], inplace=True) \n",
    "\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(label)\n",
    "\n",
    "y_test_pred = np.zeros((test.shape[0], le.classes_.shape[0]))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, label, test_size=0.2)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "X_train, X_test, test, cat_cols, num_cols = preprocess(X_train, X_test, test, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d91ce09e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\ipykernel_launcher.py:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"scaler\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:25:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: lr\n",
      "[LightGBM] [Warning] Unknown parameter: scaler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0371287\ttest: 1.0376018\tbest: 1.0376018 (0)\ttotal: 89.6ms\tremaining: 1m 29s\n",
      "100:\tlearn: 0.7281490\ttest: 0.7024621\tbest: 0.7024421 (99)\ttotal: 3.33s\tremaining: 29.7s\n",
      "200:\tlearn: 0.7099307\ttest: 0.7010177\tbest: 0.7009449 (196)\ttotal: 6.74s\tremaining: 26.8s\n",
      "300:\tlearn: 0.6951946\ttest: 0.7012524\tbest: 0.7008804 (210)\ttotal: 10.2s\tremaining: 23.8s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7008804482\n",
      "bestIteration = 210\n",
      "\n",
      "Shrink model to first 211 iterations.\n",
      "0 Fold, ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\ipykernel_launcher.py:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:28:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"scaler\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:28:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: lr\n",
      "[LightGBM] [Warning] Unknown parameter: scaler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0370137\ttest: 1.0377254\tbest: 1.0377254 (0)\ttotal: 70.8ms\tremaining: 1m 10s\n",
      "100:\tlearn: 0.7288631\ttest: 0.6938187\tbest: 0.6938187 (100)\ttotal: 3.28s\tremaining: 29.2s\n",
      "200:\tlearn: 0.7114681\ttest: 0.6923848\tbest: 0.6920092 (180)\ttotal: 6.69s\tremaining: 26.6s\n",
      "300:\tlearn: 0.6965513\ttest: 0.6919130\tbest: 0.6916339 (276)\ttotal: 9.97s\tremaining: 23.2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6916338954\n",
      "bestIteration = 276\n",
      "\n",
      "Shrink model to first 277 iterations.\n",
      "1 Fold, ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\ipykernel_launcher.py:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:30:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"scaler\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:30:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: lr\n",
      "[LightGBM] [Warning] Unknown parameter: scaler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0372992\ttest: 1.0371534\tbest: 1.0371534 (0)\ttotal: 102ms\tremaining: 1m 41s\n",
      "100:\tlearn: 0.7283221\ttest: 0.6991464\tbest: 0.6991464 (100)\ttotal: 3.15s\tremaining: 28s\n",
      "200:\tlearn: 0.7110909\ttest: 0.6976905\tbest: 0.6974219 (153)\ttotal: 6.5s\tremaining: 25.9s\n",
      "300:\tlearn: 0.6958678\ttest: 0.6967382\tbest: 0.6966620 (281)\ttotal: 9.61s\tremaining: 22.3s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6966619605\n",
      "bestIteration = 281\n",
      "\n",
      "Shrink model to first 282 iterations.\n",
      "2 Fold, ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\ipykernel_launcher.py:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:32:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"scaler\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:32:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: lr\n",
      "[LightGBM] [Warning] Unknown parameter: scaler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0371228\ttest: 1.0374974\tbest: 1.0374974 (0)\ttotal: 58.7ms\tremaining: 58.6s\n",
      "100:\tlearn: 0.7305291\ttest: 0.6973551\tbest: 0.6972415 (95)\ttotal: 2.81s\tremaining: 25s\n",
      "200:\tlearn: 0.7130038\ttest: 0.6953559\tbest: 0.6950986 (151)\ttotal: 6.21s\tremaining: 24.7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6950985728\n",
      "bestIteration = 151\n",
      "\n",
      "Shrink model to first 152 iterations.\n",
      "3 Fold, ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\ipykernel_launcher.py:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:34:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"scaler\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:34:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: lr\n",
      "[LightGBM] [Warning] Unknown parameter: scaler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0378137\ttest: 1.0360951\tbest: 1.0360951 (0)\ttotal: 64.8ms\tremaining: 1m 4s\n",
      "100:\tlearn: 0.7291197\ttest: 0.6896822\tbest: 0.6896560 (96)\ttotal: 3.23s\tremaining: 28.7s\n",
      "200:\tlearn: 0.7140427\ttest: 0.6889339\tbest: 0.6885320 (168)\ttotal: 6.73s\tremaining: 26.7s\n",
      "300:\tlearn: 0.6996668\ttest: 0.6885173\tbest: 0.6884580 (286)\ttotal: 10.4s\tremaining: 24.1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6884579759\n",
      "bestIteration = 286\n",
      "\n",
      "Shrink model to first 287 iterations.\n",
      "4 Fold, ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "val_scores = list()\n",
    "# 결과 값들을 stacking 해야하기 때문에, (모델 개수, 샘플의 수, 3) 라는 차원으로 구성됩니다.\n",
    "oof_train = np.zeros((5, X_train.shape[0], 3))\n",
    "oof_test  = np.zeros((5, X_valid.shape[0], 3))\n",
    "\n",
    "# oof_pred = np.zeros((test.shape[0], 3))\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(X_train, Y_train)):\n",
    "    x_train, y_train = X_train.iloc[trn_idx, :], pd.DataFrame(Y_train).iloc[trn_idx,]\n",
    "    x_valid, y_valid = X_train.iloc[val_idx, :], pd.DataFrame(Y_train).iloc[val_idx,]\n",
    "    \n",
    "    # 전처리\n",
    "    \n",
    "    # 모델 정의\n",
    "    models = [RandomForestClassifier(**RF_model.get_params()),\n",
    "              XGBClassifier(**XGB_params),\n",
    "              LGBMClassifier(**LGB_params),\n",
    "              SVC(**SVM.get_params())]\n",
    "            \n",
    "    for j, model in enumerate(models):\n",
    "        # 모델 학습\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # j번째 칸에 맞는 결과 담기.\n",
    "        oof_train[j, val_idx,] += model.predict_proba(x_valid)\n",
    "        oof_test[j, :,]        += model.predict_proba(X_valid) / n_splits\n",
    "    \n",
    "    cat = CatBoostClassifier(**cat_model.get_params())\n",
    "    \n",
    "    train_data = Pool(data=x_train, label=y_train, cat_features=cat_cols)\n",
    "    valid_data = Pool(data=x_valid, label=y_valid, cat_features=cat_cols)\n",
    "    \n",
    "    cat.fit(train_data, eval_set=valid_data, \n",
    "          use_best_model=True, \n",
    "          early_stopping_rounds=100, \n",
    "          verbose=100)\n",
    "    \n",
    "    oof_train[4, val_idx,] += cat.predict_proba(x_valid)\n",
    "    oof_test[4, :,]        += cat.predict_proba(X_test) / n_splits\n",
    "    \n",
    "    print(f'{i} Fold, ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f53e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5c9ee56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5292, 3)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "afc278d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21165, 15), (21165,))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "85d0e7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5292, 15), (5292,))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a6337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576ef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c79c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da70645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2b0acb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.DataFrame(np.concatenate(oof_train, axis=1))\n",
    "new_test  = pd.DataFrame(np.concatenate(oof_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e61486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "84ea0c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\hltorch\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:56:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0 Fold, train logloss : 0.38124, validation logloss : 0.7267\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10000,3) (5292,3) (10000,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-188-0b42c520aa7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# 반드시 log의 역함수인 exp를 취해주세요.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0moof_pred\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_x_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10000,3) (5292,3) (10000,3) "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "val_scores = list()\n",
    "oof_pred  = np.zeros((test.shape[0], 3))\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(new_train, Y_train)):\n",
    "    x_train, y_train = new_train.iloc[trn_idx, :], Y_train[trn_idx]\n",
    "    x_valid, y_valid = new_train.iloc[val_idx, :], Y_train[val_idx]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train     = scaler.transform(x_train)\n",
    "    x_valid     = scaler.transform(x_valid)\n",
    "    new_x_test  = scaler.transform(new_test)\n",
    "\n",
    "    # 모델 정의\n",
    "    model = XGBClassifier(random_state=42, n_jobs=(n_cpus-1))\n",
    "    \n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 훈련, 검증 데이터 log_loss 확인\n",
    "    trn_logloss = log_loss(y_train, model.predict_proba(x_train))\n",
    "    val_logloss = log_loss(y_valid, model.predict_proba(x_valid))\n",
    "    print('{} Fold, train logloss : {:.4f}4, validation logloss : {:.4f}'.format(i, trn_logloss, val_logloss))\n",
    "    \n",
    "    val_scores.append(val_logloss)\n",
    "    \n",
    "    # 반드시 log의 역함수인 exp를 취해주세요.\n",
    "    oof_pred += model.predict_proba(new_x_test) / n_splits\n",
    "    \n",
    "\n",
    "# 교차 검증 log loss 평균 계산하기\n",
    "print('Cross Validation Score : {:.5f}'.format(np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef048ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.iloc[:, 1:] = oof_pred\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcdf3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f265d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6bfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4629c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3482a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28796a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b7ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca48cedc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63516e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690c2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
