{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20463435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import multiprocessing\n",
    "\n",
    "n_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, PowerTransformer\n",
    "from sklearn.metrics import log_loss\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53f2227",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/HwaLang/Desktop/python/T academy/Kaggle_camp/'\n",
    "\n",
    "scaler_dict = {\n",
    "    \"minmax\": MinMaxScaler,\n",
    "    \"standard\": StandardScaler   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8d38938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_scaler(name):\n",
    "    print(f\"Select {name} Scaler\")\n",
    "    \n",
    "    return scaler_dict[name]()\n",
    "\n",
    "def preprocess(x_train, x_valid, x_test, params, target):\n",
    "    # global num_columns, cat_columns\n",
    "\n",
    "    tmp_x_train = x_train.copy()\n",
    "    tmp_x_valid = x_valid.copy()    \n",
    "    tmp_x_test  = x_test.copy()\n",
    "# ---------------------------\n",
    "    tmp_x_train.drop(columns = ['FLAG_MOBIL'], inplace = True)\n",
    "    tmp_x_valid.drop(columns = ['FLAG_MOBIL'], inplace = True)\n",
    "    tmp_x_test.drop(columns = ['FLAG_MOBIL'], inplace = True)\n",
    "\n",
    "    tmp_x_train['DAYS_EMPLOYED'] = tmp_x_train['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "    tmp_x_valid['DAYS_EMPLOYED'] = tmp_x_valid['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "    tmp_x_test['DAYS_EMPLOYED'] = tmp_x_test['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "\n",
    "    feats = ['DAYS_BIRTH', 'begin_month', 'DAYS_EMPLOYED']\n",
    "    for feat in feats:\n",
    "        tmp_x_train[feat]=np.abs(tmp_x_train[feat])\n",
    "        tmp_x_valid[feat]=np.abs(tmp_x_valid[feat])\n",
    "        tmp_x_test[feat]=np.abs(tmp_x_test[feat])\n",
    "    \n",
    "    for df in [tmp_x_train, tmp_x_valid, tmp_x_test]:\n",
    "        # before_EMPLOYED: 고용되기 전까지의 일수\n",
    "        df['before_EMPLOYED'] = df['DAYS_BIRTH'] - df['DAYS_EMPLOYED']\n",
    "        df['income_total_befofeEMP_ratio'] = df['income_total'] / df['before_EMPLOYED']\n",
    "        df['before_EMPLOYED_m'] = np.floor(df['before_EMPLOYED'] / 30) - ((np.floor(df['before_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "        df['before_EMPLOYED_w'] = np.floor(df['before_EMPLOYED'] / 7) - ((np.floor(df['before_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "        \n",
    "        #DAYS_BIRTH 파생변수- Age(나이), 태어난 월, 태어난 주(출생연도의 n주차)\n",
    "        df['Age'] = df['DAYS_BIRTH'] // 365\n",
    "        df['DAYS_BIRTH_m'] = np.floor(df['DAYS_BIRTH'] / 30) - ((np.floor(df['DAYS_BIRTH'] / 30) / 12).astype(int) * 12)\n",
    "        df['DAYS_BIRTH_w'] = np.floor(df['DAYS_BIRTH'] / 7) - ((np.floor(df['DAYS_BIRTH'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "        \n",
    "        #DAYS_EMPLOYED_m 파생변수- EMPLOYED(근속연수), DAYS_EMPLOYED_m(고용된 달) ,DAYS_EMPLOYED_w(고용된 주(고용연도의 n주차))  \n",
    "        df['EMPLOYED'] = df['DAYS_EMPLOYED'] // 365\n",
    "        df['DAYS_EMPLOYED_m'] = np.floor(df['DAYS_EMPLOYED'] / 30) - ((np.floor(df['DAYS_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "        df['DAYS_EMPLOYED_w'] = np.floor(df['DAYS_EMPLOYED'] / 7) - ((np.floor(df['DAYS_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "        #ability: 소득/(살아온 일수+ 근무일수)\n",
    "        df['ability'] = df['income_total'] / (df['DAYS_BIRTH'] + df['DAYS_EMPLOYED'])\n",
    "        \n",
    "        #income_mean: 소득/ 가족 수\n",
    "        df['income_mean'] = df['income_total'] / df['family_size']\n",
    "        \n",
    "        #ID 생성: 각 컬럼의 값들을 더해서 고유한 사람을 파악(*한 사람이 여러 개 카드를 만들 가능성을 고려해 begin_month는 제외함)\n",
    "        df['ID'] = \\\n",
    "        df['child_num'].astype(str) + '_' + df['income_total'].astype(str) + '_' +\\\n",
    "        df['DAYS_BIRTH'].astype(str) + '_' + df['DAYS_EMPLOYED'].astype(str) + '_' +\\\n",
    "        df['work_phone'].astype(str) + '_' + df['phone'].astype(str) + '_' +\\\n",
    "        df['email'].astype(str) + '_' + df['family_size'].astype(str) + '_' +\\\n",
    "        df['gender'].astype(str) + '_' + df['car'].astype(str) + '_' +\\\n",
    "        df['reality'].astype(str) + '_' + df['income_type'].astype(str) + '_' +\\\n",
    "        df['edu_type'].astype(str) + '_' + df['family_type'].astype(str) + '_' +\\\n",
    "        df['house_type'].astype(str) + '_' + df['occyp_type'].astype(str)\n",
    "\n",
    "    cols = ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED',]\n",
    "    tmp_x_train.drop(cols, axis=1, inplace=True)\n",
    "    tmp_x_valid.drop(cols, axis=1, inplace=True)\n",
    "    tmp_x_test.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "    cat_columns = [c for (c, t) in zip(tmp_x_train.dtypes.index, tmp_x_train.dtypes) if t == 'O'] \n",
    "    num_columns = [c for c in tmp_x_train.columns if c not in cat_columns]\n",
    "\n",
    "    YJ_transform = PowerTransformer(method='yeo-johnson')\n",
    "    tmp_x_train['income_total'] = YJ_transform.fit_transform(tmp_x_train['income_total'].values.reshape(-1, 1))\n",
    "    tmp_x_valid['income_total'] = YJ_transform.transform(tmp_x_valid['income_total'].values.reshape(-1, 1))\n",
    "    tmp_x_test['income_total'] = YJ_transform.transform(tmp_x_test['income_total'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "    tmp_x_train.reset_index(drop=True, inplace=True)\n",
    "    tmp_x_valid.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    num_columns.remove(\"income_total\")\n",
    "\n",
    "    scaler = select_scaler(params['scaler'])\n",
    "    tmp_x_train[num_columns] = scaler.fit_transform(tmp_x_train[num_columns])\n",
    "    tmp_x_valid[num_columns] = scaler.transform(tmp_x_valid[num_columns])\n",
    "    tmp_x_test[num_columns]  = scaler.transform(tmp_x_test[num_columns])\n",
    "\n",
    "    ode = OrdinalEncoder(cat_columns)\n",
    "    tmp_x_train[cat_columns] = ode.fit_transform(tmp_x_train[cat_columns], target)\n",
    "    tmp_x_valid[cat_columns] = ode.transform(tmp_x_valid[cat_columns])\n",
    "    tmp_x_test[cat_columns]  = ode.transform(tmp_x_test[cat_columns])\n",
    "\n",
    "    tmp_x_train['ID'] = tmp_x_train['ID'].astype('int64')\n",
    "    tmp_x_valid['ID'] = tmp_x_valid['ID'].astype('int64')\n",
    "    tmp_x_test['ID'] = tmp_x_test['ID'].astype('int64')\n",
    "\n",
    "# ---------------------------    \n",
    "    return tmp_x_train, tmp_x_valid, tmp_x_test\n",
    "\n",
    "def make_submission(y_test_pred, val_loss):\n",
    "    ''' \n",
    "        내용 추가\n",
    "        제출 파일 생성 함수 작성\n",
    "    '''\n",
    "    submit_path = join(BASE_DIR, 'data', 'MDC14', 'sample_submission.csv')\n",
    "    df_result = pd.read_csv(submit_path)\n",
    "    df_result.iloc[:, 1:] = y_test_pred\n",
    "    df_result.to_csv('./temp/model_loss_{:.4f}.csv'.format(val_loss), index=False)\n",
    "\n",
    "    pass\n",
    "\n",
    "def main(bagging_temperature, depth, learning_rate, min_data_in_leaf, border_count):\n",
    "    params = {}\n",
    "    params[\"bagging_temperature\"]= int(round(bagging_temperature))\n",
    "    params[\"depth\"]= int(round(depth))\n",
    "    params[\"learning_rate\"]= learning_rate\n",
    "    params[\"min_data_in_leaf\"]= int(round(min_data_in_leaf))\n",
    "    params[\"border_count\"]= int(round(border_count))\n",
    "    params[\"scaler\"]= \"standard\"\n",
    "\n",
    "    # 데이터 경로 입력\n",
    "    train_path = join(BASE_DIR, 'data', 'MDC14', 'train.csv')\n",
    "    test_path  = join(BASE_DIR, 'data', 'MDC14', 'test.csv')\n",
    "\n",
    "    data = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "\n",
    "    data.fillna(\"NaN\", inplace = True)\n",
    "    test.fillna(\"NaN\", inplace = True)\n",
    "\n",
    "    label = data['credit'] \n",
    "\n",
    "    data.drop(columns=['index', 'credit'], inplace=True)\n",
    "    test.drop(columns=['index'], inplace=True) \n",
    "\n",
    "    le = LabelEncoder()\n",
    "    label = le.fit_transform(label)\n",
    "    \n",
    "    # 대회에 맞는 차원 입력\n",
    "    y_test_pred = np.zeros((test.shape[0], le.classes_.shape[0]))\n",
    "\n",
    "    cv_scores = list()\n",
    "\n",
    "    # 예측하려는 유형에 따라 KFold or StratifiedKFold 선택\n",
    "    n_splits = 3\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, valid_index in skf.split(data, label):\n",
    "        x_train, y_train = data.iloc[train_index, :], label[train_index]\n",
    "        x_valid, y_valid = data.iloc[valid_index, :], label[valid_index]\n",
    "\n",
    "        x_train, x_valid, x_test = preprocess(x_train, x_valid, test, params, y_train)\n",
    "\n",
    "        model = CatBoostClassifier(bagging_temperature = params[\"bagging_temperature\"],\n",
    "                                   depth               = params[\"depth\"],\n",
    "                                   learning_rate       = params[\"learning_rate\"],\n",
    "                                   min_data_in_leaf    = params[\"min_data_in_leaf\"],\n",
    "                                   border_count        = params[\"border_count\"])\n",
    "\n",
    "        cat_cols = ['income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type', 'ID']\n",
    "        \n",
    "        train_data = Pool(data=x_train, label=y_train, cat_features=cat_cols)\n",
    "        valid_data = Pool(data=x_valid, label=y_valid, cat_features=cat_cols)\n",
    "        \n",
    "        model.fit(train_data, eval_set=valid_data, \n",
    "                  use_best_model=True, \n",
    "                  early_stopping_rounds=100, \n",
    "                  verbose=100)\n",
    "\n",
    "        valid_loss = log_loss(y_valid, model.predict_proba(x_valid))\n",
    "\n",
    "        cv_scores.append(valid_loss)\n",
    "\n",
    "        y_test_pred += model.predict_proba(x_test) / skf.n_splits\n",
    "\n",
    "    cv_loss = np.mean(cv_scores)\n",
    "\n",
    "    print('Cross validation Loss: %.4f' % cv_loss)\n",
    "\n",
    "#     nni.report_final_result(cv_loss)\n",
    "    print('Final result is %g', cv_loss)\n",
    "    print('Send final result done.')\n",
    "\n",
    "    make_submission(y_test_pred, cv_loss)\n",
    "    return cv_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d069bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967b062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1068499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | border... |   depth   | learni... | min_da... |\n",
      "-------------------------------------------------------------------------------------\n",
      "Select standard Scaler\n",
      "0:\tlearn: 1.0052807\ttest: 1.0065048\tbest: 1.0065048 (0)\ttotal: 170ms\tremaining: 2m 49s\n",
      "100:\tlearn: 0.6244247\ttest: 0.7779232\tbest: 0.7779232 (100)\ttotal: 3.63s\tremaining: 32.3s\n",
      "200:\tlearn: 0.4961966\ttest: 0.7535841\tbest: 0.7535841 (200)\ttotal: 7.09s\tremaining: 28.2s\n",
      "300:\tlearn: 0.4171267\ttest: 0.7532225\tbest: 0.7513642 (255)\ttotal: 10.5s\tremaining: 24.4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7513641766\n",
      "bestIteration = 255\n",
      "\n",
      "Shrink model to first 256 iterations.\n",
      "Select standard Scaler\n",
      "0:\tlearn: 1.0238849\ttest: 1.0264917\tbest: 1.0264917 (0)\ttotal: 32.9ms\tremaining: 32.9s\n",
      "100:\tlearn: 0.6095358\ttest: 0.7790321\tbest: 0.7790321 (100)\ttotal: 3.46s\tremaining: 30.8s\n",
      "200:\tlearn: 0.4802686\ttest: 0.7571650\tbest: 0.7571650 (200)\ttotal: 7.17s\tremaining: 28.5s\n",
      "300:\tlearn: 0.4021812\ttest: 0.7582551\tbest: 0.7554664 (254)\ttotal: 10.8s\tremaining: 25s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7554663617\n",
      "bestIteration = 254\n",
      "\n",
      "Shrink model to first 255 iterations.\n",
      "Select standard Scaler\n",
      "0:\tlearn: 0.9993916\ttest: 0.9999841\tbest: 0.9999841 (0)\ttotal: 36.2ms\tremaining: 36.1s\n",
      "100:\tlearn: 0.6039683\ttest: 0.7709231\tbest: 0.7709231 (100)\ttotal: 3.49s\tremaining: 31.1s\n",
      "200:\tlearn: 0.4861183\ttest: 0.7615541\tbest: 0.7614807 (199)\ttotal: 6.9s\tremaining: 27.4s\n",
      "300:\tlearn: 0.4088302\ttest: 0.7636429\tbest: 0.7603373 (216)\ttotal: 10.3s\tremaining: 24s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7603372995\n",
      "bestIteration = 216\n",
      "\n",
      "Shrink model to first 217 iterations.\n",
      "Cross validation Loss: 0.7557\n",
      "Final result is %g 0.7557226126309519\n",
      "Send final result done.\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7557  \u001b[0m | \u001b[0m 29.74   \u001b[0m | \u001b[0m 191.2   \u001b[0m | \u001b[0m 8.061   \u001b[0m | \u001b[0m 0.1888  \u001b[0m | \u001b[0m 5.6     \u001b[0m |\n",
      "Select standard Scaler\n",
      "0:\tlearn: 1.0679853\ttest: 1.0749286\tbest: 1.0749286 (0)\ttotal: 4.41s\tremaining: 1h 13m 30s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\miniconda3\\envs\\hlpy37\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (20.29627589389861, 20.046688142617665, 15.898067850202551, 0.07741247165375328, 1.7404772235567285)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5f6ef74874a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m optimizer.maximize(\n\u001b[0;32m     15\u001b[0m     \u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m )\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hlpy37\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hlpy37\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hlpy37\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-8955b616e1c7>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(bagging_temperature, depth, learning_rate, min_data_in_leaf, border_count)\u001b[0m\n\u001b[0;32m    164\u001b[0m                   \u001b[0muse_best_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m                   \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m                   verbose=100)\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hlpy37\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   4675\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0;32m   4676\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4677\u001b[1;33m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0m\u001b[0;32m   4678\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hlpy37\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2000\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2002\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2003\u001b[0m             )\n\u001b[0;32m   2004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hlpy37\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1427\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1428\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1429\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pbounds = {\n",
    "    \"bagging_temperature\":[1, 30],\n",
    "    \"depth\":[1, 16],\n",
    "    \"learning_rate\" :[0.05,0.5],\n",
    "    \"min_data_in_leaf\" :[1,6],\n",
    "    \"border_count\":[1, 255]\n",
    "    }\n",
    "optimizer = BayesianOptimization(\n",
    "    f = main,\n",
    "    pbounds = pbounds,\n",
    "    random_state = 1324\n",
    ")\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3260d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"bagging_temperature\":10,\n",
    "    \"depth\":5,\n",
    "    \"learning_rate\" :0.01,\n",
    "    \"min_data_in_leaf\" :3,\n",
    "    \"border_count\":150,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5e9818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select standard Scaler\n",
      "0:\tlearn: 1.0941691\ttest: 1.0941691\tbest: 1.0941691 (0)\ttotal: 8.13ms\tremaining: 8.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 0.9130367\ttest: 0.9130367\tbest: 0.9130367 (100)\ttotal: 342ms\tremaining: 3.04s\n",
      "200:\tlearn: 0.8869650\ttest: 0.8869650\tbest: 0.8869650 (200)\ttotal: 660ms\tremaining: 2.63s\n",
      "300:\tlearn: 0.8830838\ttest: 0.8830838\tbest: 0.8830838 (300)\ttotal: 979ms\tremaining: 2.27s\n",
      "400:\tlearn: 0.8825342\ttest: 0.8825342\tbest: 0.8825342 (400)\ttotal: 1.31s\tremaining: 1.95s\n",
      "500:\tlearn: 0.8824588\ttest: 0.8824588\tbest: 0.8824588 (500)\ttotal: 1.63s\tremaining: 1.62s\n",
      "600:\tlearn: 0.8824486\ttest: 0.8824486\tbest: 0.8824486 (600)\ttotal: 1.95s\tremaining: 1.29s\n",
      "700:\tlearn: 0.8824472\ttest: 0.8824472\tbest: 0.8824472 (700)\ttotal: 2.27s\tremaining: 968ms\n",
      "800:\tlearn: 0.8824470\ttest: 0.8824470\tbest: 0.8824470 (800)\ttotal: 2.6s\tremaining: 645ms\n",
      "900:\tlearn: 0.8824470\ttest: 0.8824470\tbest: 0.8824470 (900)\ttotal: 3.01s\tremaining: 330ms\n",
      "999:\tlearn: 0.8824470\ttest: 0.8824470\tbest: 0.8824470 (999)\ttotal: 3.35s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8824470071\n",
      "bestIteration = 999\n",
      "\n",
      "Select standard Scaler\n",
      "0:\tlearn: 1.0941691\ttest: 1.0941691\tbest: 1.0941691 (0)\ttotal: 8.27ms\tremaining: 8.26s\n",
      "100:\tlearn: 0.9130367\ttest: 0.9130367\tbest: 0.9130367 (100)\ttotal: 380ms\tremaining: 3.38s\n",
      "200:\tlearn: 0.8869650\ttest: 0.8869650\tbest: 0.8869650 (200)\ttotal: 715ms\tremaining: 2.84s\n",
      "300:\tlearn: 0.8830838\ttest: 0.8830838\tbest: 0.8830838 (300)\ttotal: 1.07s\tremaining: 2.48s\n",
      "400:\tlearn: 0.8825342\ttest: 0.8825342\tbest: 0.8825342 (400)\ttotal: 1.42s\tremaining: 2.12s\n",
      "500:\tlearn: 0.8824588\ttest: 0.8824588\tbest: 0.8824588 (500)\ttotal: 1.74s\tremaining: 1.73s\n",
      "600:\tlearn: 0.8824486\ttest: 0.8824486\tbest: 0.8824486 (600)\ttotal: 2.08s\tremaining: 1.38s\n",
      "700:\tlearn: 0.8824472\ttest: 0.8824472\tbest: 0.8824472 (700)\ttotal: 2.43s\tremaining: 1.04s\n",
      "800:\tlearn: 0.8824470\ttest: 0.8824470\tbest: 0.8824470 (800)\ttotal: 2.82s\tremaining: 701ms\n",
      "900:\tlearn: 0.8824470\ttest: 0.8824470\tbest: 0.8824470 (900)\ttotal: 3.21s\tremaining: 353ms\n",
      "999:\tlearn: 0.8824470\ttest: 0.8824470\tbest: 0.8824470 (999)\ttotal: 3.61s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8824470071\n",
      "bestIteration = 999\n",
      "\n",
      "Select standard Scaler\n"
     ]
    }
   ],
   "source": [
    "main(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad622e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328f8e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b22f6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea3f2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5357a59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3dfadf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
