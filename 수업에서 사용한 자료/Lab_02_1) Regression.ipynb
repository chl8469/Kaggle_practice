{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxQ2YTAv4tB-"
   },
   "source": [
    "# Week 2\n",
    "\n",
    "### Context\n",
    "#### Regression\n",
    "+ Linear Regression\n",
    "+ Ridge Linear Regression(L1)\n",
    "+ Lasso Linear Regression(L2)\n",
    "\n",
    "#### Evaluation\n",
    "+ R<sup>2</sup>\n",
    "+ MAE, MSE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAfXTYpj5ysB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = ''\n",
    "\n",
    "train_path = join(BASE_DIR, 'data', 'MDC14', 'train.csv')\n",
    "test_path  = join(BASE_DIR, 'data', 'MDC14', 'test.csv')\n",
    "\n",
    "data = pd.read_csv(train_path)\n",
    "x_test = pd.read_csv(test_path)\n",
    "\n",
    "label = data['credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 컬럼 제거\n",
    "data.drop(columns=['index', 'credit'], inplace=True)\n",
    "x_test.drop(columns=['index'],         inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [c for c, t in zip(data.dtypes.index, data.dtypes) if t == 'O'] \n",
    "num_columns = [c for c    in data.columns if c not in cat_columns]\n",
    "\n",
    "print('Categorical Columns: \\n{}\\n'.format(cat_columns))\n",
    "print('Numeric Columns: \\n{}'.format(num_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 결측치 확인 및 결측치 처리 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 수치형 변수들의 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(data[num_columns]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(x_test[num_columns]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 범주형 변수들의 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(data[cat_columns]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(x_test[cat_columns]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 쪼개기, Train -> (Train, Valid)\n",
    "- train_test_split 파라미터 \n",
    "    - test_size  (float): Valid(test)의 크기의 비율을 지정\n",
    "    - random_state (int): 데이터를 쪼갤 때 내부적으로 사용되는 난수 값 (해당 값을 지정하지 않으면 매번 달라집니다.)\n",
    "    - shuffle     (bool): 데이터를 쪼갤 때 섞을지 유무\n",
    "    - stratify   (array): Stratify란, 쪼개기 이전의 클래스 비율을 쪼개고 나서도 유지하기 위해 설정해야하는 값입니다. 클래스 라벨을 넣어주면 됩니다.\n",
    "        - ex) 원본 Train 데이터의 클래스 비율이 (7:3) 이었다면, 쪼개어진 Train, Valid(test) 데이터의 클래스 비율도 (7:3)이 됩니다. 당연히 분류 데이터에서만 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쪼개어진 Train, Valid 데이터의 비율은 (7:3), 내부 난수 값 42, 데이터를 쪼갤 때 섞으며 label 값으로 Stratify 하는 코드 입니다. random_state를 주석 처리하고 데이터를 확인해보시면 계속 바뀝니다.\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data, label, \n",
    "                                                      test_size=0.3,\n",
    "                                                      random_state=42,\n",
    "                                                      shuffle=True,\n",
    "                                                      stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쪼갠 데이터의 인덱스는 정리해주는것이 좋습니다. pd.concat 연산 시, 인덱스를 기준으로 연결하기 때문입니다.\n",
    "# drop 인자를 True로 주지 않으면 이전 인덱스가 새로운 변수로 생성됩니다.\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "x_valid = x_valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 전처리 실습 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 결측치 처리\n",
    "`occyp_type` 변수 최빈 값으로 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "x_train[cat_columns] = imputer.fit_transform(x_train[cat_columns])\n",
    "x_valid[cat_columns] = imputer.transform(x_valid[cat_columns])\n",
    "x_test[cat_columns]  = imputer.transform(x_test[cat_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mean = np.mean(x_train[num_columns], axis=0)\n",
    "x_train_std  = np.std(x_train[num_columns], axis=0)\n",
    "\n",
    "# Numpy 브로드캐스팅 기능을 활용해 x_train의 평균과 표준편차로 x_train, x_valid의 스케일링을 진행해줍니다.\n",
    "x_train.loc[:, num_columns] = (x_train[num_columns] - x_train_mean) / (x_train_std + 1e-10)\n",
    "x_valid.loc[:, num_columns] = (x_valid[num_columns] - x_train_mean) / (x_train_std + 1e-10)\n",
    "x_test.loc[:, num_columns]  = (x_test[num_columns]  - x_train_mean) / (x_train_std + 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 스케일링 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[num_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid[num_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[num_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 왜 x_valid와 x_test는 평균이 0, 표준편차가 1이 아닌가요? -> x_train의 평균과 표준편차를 사용했기 때문에 x_valid의 평균과 표준편차가 0, 1이 아닐 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 범주형 변수 OneHot Encoding, 라벨 변수 Label Encoding \n",
    "- 범주형 변수 OneHot Encoding 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "ohe.fit(x_train[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_x_train_cat = ohe.transform(x_train[cat_columns])\n",
    "# new_x_valid_cat = ohe.transform(x_valid[cat_columns])\n",
    "# new_x_test_cat = ohe.transform(x_test[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 둘다 가능\n",
    "x_all = pd.concat([x_train[cat_columns], x_valid[cat_columns], x_test[cat_columns]], axis=0)\n",
    "\n",
    "# 전체에 대해 fiting\n",
    "ohe.fit(x_all)\n",
    "\n",
    "# ohe.categories_ 은 입력된 범주형 컬럼의 범주 값을 순서대로 담고 있습니다.\n",
    "ohe_columns = ohe.categories_[0].tolist()\n",
    "for col in ohe.categories_[1:]:\n",
    "    ohe_columns += col.tolist()\n",
    "ohe_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_train_cat = pd.DataFrame(ohe.transform(x_train[cat_columns]), columns=ohe_columns)\n",
    "new_x_valid_cat = pd.DataFrame(ohe.transform(x_valid[cat_columns]), columns=ohe_columns)\n",
    "new_x_test_cat  = pd.DataFrame(ohe.transform(x_test[cat_columns]),  columns=ohe_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set 개수 확인\n",
    "new_x_train_cat.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid set 개수 확인\n",
    "new_x_valid_cat.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 개수 확인\n",
    "new_x_test_cat.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일하게 데이터를 쪼갤 시 인덱스를 초기화합니다.\n",
    "new_x_train_cat.reset_index(drop=True, inplace=True)\n",
    "new_x_valid_cat.reset_index(drop=True, inplace=True)\n",
    "new_x_test_cat.reset_index(drop=True,  inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 기존 범주형 변수를 제거하고, Onehot Encoding된 변수를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 범주형 변수 제거\n",
    "x_train.drop(columns=cat_columns, inplace=True)\n",
    "x_valid.drop(columns=cat_columns, inplace=True)\n",
    "x_test.drop(columns=cat_columns,  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onehot Encoding 변수 추가\n",
    "x_train = pd.concat([x_train[num_columns], new_x_train_cat], axis=1)\n",
    "x_valid = pd.concat([x_valid[num_columns], new_x_valid_cat], axis=1)\n",
    "x_test  = pd.concat([x_test[num_columns],  new_x_test_cat],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 확인\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid 확인\n",
    "x_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 확인\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_valid = y_valid.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주의!! 분류 라벨 데이터가지고 회귀 모델로 예측하는건 잘못된 겁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "선형 회귀는 종속 변수와 한개 이상의 독립 변수와의 선형 상관 관계를 모델링하는 회귀 분석 기법입니다. <br>\n",
    "용어를 종속 변수, 독립 변수로 표현하면 이해하기 어려우니 다음 수식에서의 y, x 로 표현하겠습니다.<br> \n",
    "\n",
    "$$ y = wx + b$$\n",
    "$$ y = w_0x_0 + w_1x_1 + w_2x_2 + .... w_nx_n + b$$\n",
    "$$ w : 계수(가중치) $$\n",
    "$$ b : 절편(편향) $$\n",
    "\n",
    "간단하게 생각해보면 선형 회귀는 데이터가 분포되어 있는 공간에서 데이터를 가장 잘 표현하는 선을 하나 긋는다고 생각할 수 있습니다.<br>\n",
    "선형 회귀의 비용 함수는 다음과 같이 표현될 수 있습니다.\n",
    "\n",
    "$$ Cost_{lr} = \\sum_i{(y_i - \\hat y_i)^2}$$\n",
    "$$ \\hat y_i = b + wx_i $$\n",
    "\n",
    "결국 실제 참값 $y_i$와 회귀 모델이 출력한 $ \\hat y $ 사이의 잔차의 제곱의 합을 최소화하는 w(계수)를 구하는 것이 목적입니다. -> Least Square, 최소 제곱법 <br>\n",
    "선형 회귀는 출력되는 y가 1개 또는 2개 이상인지의 유무에 따라 단변량, 다변량이라는 말이 붙는데, 이번 수업에서는 출력값인 y가 1개(단변량)라고 가정하겠습니다. <br>\n",
    "또한, 입력으로 들어가는 x가 1개 또는 2개 이상인지의 유무에 따라 단순(Simple), 다중(Multiple)이라는 말이 붙는데, 이번 실습에서는 단순, 다중 선형 회귀 분석에 대해 모두 알아보겠습니다.\n",
    "\n",
    "#### 선형 회귀분석의 4가지 기본 가정\n",
    "선형 회귀에는 4가지 가정이 필요합니다. 우리 수업에서는 이론적인 내용을 다루지 않으므로, 추후에 살펴보시면 좋겠습니다.<br>\n",
    "맨 아래 참조 목록에 4가지 가정에 대해 잘 설명해준 페이지의 링크를 달아두었습니다.\n",
    "1. 선형성\n",
    "2. 독립성\n",
    "3. 등분산성\n",
    "4. 정규성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear Regression\n",
    "\n",
    "- 하나의 연속 변수를 예측하는 선형 회귀에는 \"단순\" 선형 회귀(Simple Linear Regression), \"다중\" 선형 회귀(Multiple Linear Regression)가 있습니다. \"단순\" 선형 회귀는 입력 데이터의 변수가 1개인 경우이고, \"다중\" 선형 회귀는 입력 데이터의 변수가 2개 이상인 경우 입니다.\n",
    "- 일반적으로는 여러 변수를 사용하는 \"다중\" 회귀 분석이 되겠습니다.\n",
    "\n",
    "Linear Regression은 Sklearn의 linear_model 패키지에 있습니다.\n",
    "\n",
    "- Linear Regression 대표적 파라미터\n",
    "    - fit_intercept (bool) : 회귀 수식에서 y 절편을 포함할지 유무\n",
    "    \n",
    "#### ref\n",
    "- [선형 회귀의 기본 가정 kkokkilkon님 블로그](https://kkokkilkon.tistory.com/175)\n",
    "- [Linear Regression, Wiki](https://ko.wikipedia.org/wiki/선형_회귀)\n",
    "- [Scikit-learn, Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 모델 불러오기 및 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 모델 학습하기 (훈련 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 결과 예측하기 (검증 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 결과 살펴보기\n",
    "일반적으로 선형회귀 R<sup>2</sup>를 평가 척도로 사용합니다.<br>\n",
    "R<sup>2</sup>값이 1에 가까울수록 회귀 모델이 데이터를 잘 표현한다는 것을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print('선형 회귀, R2 : {:.4f}'.format(r2_score(y_valid, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회귀 모델의 계수 w, 절편 b 살펴보기\n",
    "어떤 변수에 얼마 만큼의 가중치가 할당되고, 절편 값은 얼마나 할당되는지 살펴볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('다중 선형 회귀, 계수(w) : {}, 절편(b) : {:.4f}'.format(lr.coef_, lr.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lasso Linear Regression(L1)\n",
    "이번에는 선형 회귀 모델의 가중치 크기에 규제를 적용하는 라쏘 선형 회귀 모델을 살펴보겠습니다.<br>\n",
    "라쏘 선형 회귀 모델과 기존 선형 회귀 모델의 차이점으로는 손실 함수에 L1 정규화 항을 추가하는 것인데, 다음과 같습니다. \n",
    "\n",
    "$$ Cost_{lr} = \\sum_i{(y_i - \\hat y_i)^2} + \\lambda \\sum{|w|}$$\n",
    "\n",
    "해당 식에서 w는 선형 회귀 모델이 가진 가중치 값으로, 학습을 통해 손실 함수를 최소화하면 각 가중치의 값도 작아지는 효과를 얻을 수 있습니다.<br>\n",
    "이는 선형 회귀 모델의 과적합을 방지하는 요소로써 사용되어지는데, 가중치의 값이 클 경우 모델의 복잡도가 높아져서 과적합되는 경향이 있기 때문입니다. <br>\n",
    "라쏘 선형 회귀는 몇몇 가중치의 값을 0으로 만드는 특징이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lasso Linear Regression 대표적 파라미터\n",
    "    - alpha         (float): L1 규제를 얼마나 많이 적용할지에 대한 수치 \n",
    "    - fit_intercept (bool) : 회귀 수식에서 y 절편을 포함할지 유무\n",
    "    - random_state  (int)  : 내부적으로 사용되는 난수값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 모델 불러오기 및 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_lr = Lasso(alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 모델 학습하기 (훈련 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 결과 예측하기 (검증 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso_lr.predict(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 결과 살펴보기\n",
    "일반적으로 선형회귀 R<sup>2</sup>를 평가 척도로 사용합니다.<br>\n",
    "R<sup>2</sup>값이 1에 가까울수록 회귀 모델이 데이터를 잘 표현한다는 것을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('라쏘 선형 회귀, R2 : {:.4f}'.format(r2_score(y_valid, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회귀 모델의 계수 w, 절편 b 살펴보기\n",
    "어떤 변수에 얼마 만큼의 가중치가 할당되고, 절편 값은 얼마나 할당되는지 살펴볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('라쏘 선형 회귀, 계수(w) : {}, 절편(b) : {:.4f}'.format(lasso_lr.coef_, lasso_lr.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Ridge Linear Regression(L2)\n",
    "이번에는 선형 회귀 모델의 가중치 크기에 규제를 적용하는 릿지 선형 회귀 모델을 살펴보겠습니다.<br>\n",
    "릿지 선형 회귀 모델과 기존 선형 회귀 모델의 차이점으로는 손실 함수에 L2 정규화 항을 추가하는 것인데, 다음과 같습니다. \n",
    "\n",
    "$$ Cost_{lr} = \\sum_i{(y_i - \\hat y_i)^2} + \\lambda \\sum{w^2}$$\n",
    "\n",
    "해당 식에서 w는 선형 회귀 모델이 가진 가중치 값으로, 학습을 통해 손실 함수를 최소화하면 각 가중치의 값도 작아지는 효과를 얻을 수 있습니다.<br>\n",
    "라쏘 선형 회귀와는 다르게 각 가중치의 값이 0이 아닌 0에 가까운 작은 수로 수렴하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lasso Linear Regression 대표적 파라미터\n",
    "    - alpha         (float): L2 규제를 얼마나 많이 적용할지에 대한 수치 \n",
    "    - fit_intercept (bool) : 회귀 수식에서 y 절편을 포함할지 유무\n",
    "    - random_state  (int)  : 내부적으로 사용되는 난수값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 모델 불러오기 및 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_lr = Ridge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 모델 학습하기 (훈련 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 결과 예측하기 (검증 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge_lr.predict(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 결과 살펴보기\n",
    "일반적으로 선형회귀 R<sup>2</sup>를 평가 척도로 사용합니다.<br>\n",
    "R<sup>2</sup>값이 1에 가까울수록 회귀 모델이 데이터를 잘 표현한다는 것을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('릿지 선형 회귀, R2 : {:.4f}'.format(r2_score(y_valid, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회귀 모델의 계수 w, 절편 b 살펴보기\n",
    "어떤 변수에 얼마 만큼의 가중치가 할당되고, 절편 값은 얼마나 할당되는지 살펴볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('릿지 선형 회귀, 계수(w) : {}, 절편(b) : {:.4f}'.format(ridge_lr.coef_, ridge_lr.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### R<sup>2</sup>\n",
    "Scikit-Learn에서 지원하는 회귀 모델의 평가 방법으로는 R<sup>2</sup>가 있습니다. <br>\n",
    "학습한 회귀 모델이 얼마나 데이터를 잘 표현하는지에 대한 정도를 나타내는 통계적인 척도이며, 0 < R<sup>2</sup> < 1 범위의 값을 갖습니다.<br>\n",
    "\n",
    "<img src = './img/R2.png' alt='R2' align='left' height=500 width=500 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ R^2 = 1 - {SSE \\over SST} = {SSR \\over SST} = {선형모형의\\ 편차 \\over 전체편차}$$\n",
    "\n",
    "* R<sup>2</sup> = 1, 모델이 데이터를 완벽하게 표현함 (Fits perfectly)\n",
    "* R<sup>2</sup> = 0, 모델이 데이터를 전혀 표현하지 못함 (Does not explain anything)\n",
    "\n",
    "- $ Var={{1}\\over{n}}{\\sum^n_{i=1}{(y_i - \\bar{y})^2}} $\n",
    "\n",
    "- SST = 분산 공식에서 샘플의 개수로 나누지 않은 수식 ~= 분산 ~= 편차\n",
    "- SSR = 회귀선이 그리는 지점에서 평균을 뺀것이기 때문에, 회귀선이 나타내는 분산 ~= 편차\n",
    "- 따라서 $R^2$는 전체 편차에 대한 회귀 식의 편차 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error(MAE)\n",
    "MAE는 회귀 모델에서 자주 사용되는 손실 함수 입니다. <br>\n",
    "MAE는 오차(정답과 예측값의 차이)의 절대 값에 대해 평균을 취한 결과 입니다. 수식은 다음과 같습니다.\n",
    "$${{1}\\over{n}} \\sum_{i=1}^n{(|y_i - \\hat{y}_i|)}$$\n",
    "\n",
    "### Mean Squared Error(MSE)\n",
    "MSE는 회귀 모델에서 자주 사용되는 손실 함수로 다음과 같은 수식으로 구성되어 있습니다. <br>\n",
    "이름에서 알 수 있듯 MAE가 오차의 절대값을 사용했다면, 오차를 제곱해서 평균을 취한 결과입니다. \n",
    "$${{1}\\over{n}} \\sum_{i=1}^n{(y_i - \\hat{y}_i)^2}$$\n",
    "\n",
    "### Root Mean Squared Error(RMSE)\n",
    "RMSE는 MSE에 Square root를 씌운것과 같습니다. 수식은 다음과 같습니다. <br>\n",
    "\n",
    "$$\\sqrt{{{1}\\over{n}} \\sum_{i=1}^n{(y_i - \\hat{y}_i)^2}}$$\n",
    "\n",
    "#### ref \n",
    "- [MAE, MSE](https://blog.naver.com/PostView.nhn?blogId=heygun&logNo=221516529668&parentCategoryNo=&categoryNo=56&viewDate=&isShowPopularPosts=true&from=search)\n",
    "- [RMSE](https://ko.wikipedia.org/wiki/평균_제곱근_편차)\n",
    "- [$R^2$](https://m.blog.naver.com/pmw9440/221822183325)\n",
    "- [Scikit-learn, MAE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html?highlight=mean%20absolute%20error#sklearn.metrics.mean_absolute_error)\n",
    "- [Scikit-learn, MSE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html?highlight=mean%20squared%20error#sklearn.metrics.mean_squared_error)\n",
    "- [Scikit-learn, $R^2$](https://www.google.com/url?q=http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html&sa=U&ved=0ahUKEwicgu3vueDhAhUI9LwKHeLDD3UQFggEMAA&client=internal-uds-cse&cx=016639176250731907682:tjtqbvtvij0&usg=AOvVaw3JYUuCpR-KNsPU189XgvWR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r2_score : {:.3f}'.format(r2_score(y_valid, y_pred)))\n",
    "print('MAE      : {:.6f}'.format(mean_absolute_error(y_valid, y_pred)))\n",
    "print('MSE      : {:.6f}'.format(mean_squared_error(y_valid, y_pred)))\n",
    "print('RMSE     : {:.6f}'.format(np.sqrt(mean_squared_error(y_valid, y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 솔루션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 전처리 실습 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 결측치 확인 및 결측치 처리 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 수치형 변수들의 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(data[num_columns]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(x_test[num_columns]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 범주형 변수들의 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(data[cat_columns]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(x_test[cat_columns]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치가 없으므로 그대로 넘어가셔도 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 쪼개기, Train -> (Train, Valid)\n",
    "- train_test_split 파라미터 \n",
    "    - test_size  (float): Valid(test)의 크기의 비율을 지정\n",
    "    - random_state (int): 데이터를 쪼갤 때 내부적으로 사용되는 난수 값 (해당 값을 지정하지 않으면 매번 달라집니다.)\n",
    "    - shuffle     (bool): 데이터를 쪼갤 때 섞을지 유무\n",
    "    - stratify   (array): Stratify란, 쪼개기 이전의 클래스 비율을 쪼개고 나서도 유지하기 위해 설정해야하는 값입니다. 클래스 라벨을 넣어주면 됩니다.\n",
    "        - ex) 원본 Train 데이터의 클래스 비율이 (7:3) 이었다면, 쪼개어진 Train, Valid(test) 데이터의 클래스 비율도 (7:3)이 됩니다. 당연히 분류 데이터에서만 사용할 수 있습니다.\n",
    "        - 이번에는 분류 문제가 아니므로 일반적으로는 stratify를 사용할 수 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쪼개어진 Train, Valid 데이터의 비율은 (7:3), 내부 난수 값 42, 데이터를 쪼갤 때 섞으며 label 값으로 Stratify 하는 코드 입니다. random_state를 주석 처리하고 데이터를 확인해보시면 계속 바뀝니다.\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data, label, \n",
    "                                                      test_size=0.3,\n",
    "                                                      random_state=42,\n",
    "                                                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쪼갠 데이터의 인덱스는 정리해주는것이 좋습니다. pd.concat 연산 시, 인덱스를 기준으로 연결하기 때문입니다.\n",
    "# drop 인자를 True로 주지 않으면 이전 인덱스가 새로운 변수로 생성됩니다.\n",
    "x_train.reset_index(drop=True, inplace=True)\n",
    "x_valid.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### x_train, x_valid, x_test에 대해 스케일링 및 범주형 변수 인코딩을 진행해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mean = np.mean(x_train[num_columns], axis=0)\n",
    "x_train_std  = np.std(x_train[num_columns], axis=0)\n",
    "\n",
    "# Numpy 브로드캐스팅 기능을 활용해 x_train의 평균과 표준편차로 x_train, x_valid의 스케일링을 진행해줍니다.\n",
    "x_train.loc[:, num_columns] = (x_train[num_columns] - x_train_mean) / (x_train_std + 1e-10)\n",
    "x_valid.loc[:, num_columns] = (x_valid[num_columns] - x_train_mean) / (x_train_std + 1e-10)\n",
    "x_test.loc[:, num_columns]  = (x_test[num_columns]  - x_train_mean) / (x_train_std + 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 스케일링 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[num_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid[num_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[num_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 왜 x_valid와 x_test는 평균이 0, 표준편차가 1이 아닌가요? -> x_train의 평균과 표준편차를 사용했기 때문에 x_valid의 평균과 표준편차가 0, 1이 아닐 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 범주형 변수 OneHot Encoding, 라벨 변수 스케일링\n",
    "- 범주형 변수 OneHot Encoding 처리, 이번에는 라벨이 수치형이므로 라벨은 인코딩하지 않습니다.\n",
    "\n",
    "#### Tip\n",
    "- 예측할 변수의 값이 너무 큰 경우 라벨 변수를 log 스케일링을 진행할 수 있습니다. 거래가는 모두 양수이므로 log를 취해 예측할 라벨의 범위를 줄일 수 있습니다.\n",
    "    - 예측 후, exp를 취해 원래 스케일로 되돌려줄 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "ohe.fit(data[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_columns = ohe.categories_[0].tolist()\n",
    "for cols in ohe.categories_[1:]:\n",
    "    ohe_columns += cols.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_train_cat = pd.DataFrame(ohe.transform(x_train[cat_columns]), columns=ohe_columns)\n",
    "new_x_valid_cat = pd.DataFrame(ohe.transform(x_valid[cat_columns]), columns=ohe_columns)\n",
    "new_x_test_cat  = pd.DataFrame(ohe.transform(x_test[cat_columns]),  columns=ohe_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set 개수 확인\n",
    "new_x_train_cat.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid set 개수 확인\n",
    "new_x_valid_cat.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 개수 확인\n",
    "new_x_test_cat.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 기존 범주형 변수를 제거하고, Onehot Encoding된 변수를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 범주형 변수 제거\n",
    "x_train.drop(columns=cat_columns, inplace=True)\n",
    "x_valid.drop(columns=cat_columns, inplace=True)\n",
    "x_test.drop(columns=cat_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onehot Encoding 변수 추가\n",
    "x_train = pd.concat([x_train, new_x_train_cat], axis=1)\n",
    "x_valid = pd.concat([x_valid, new_x_valid_cat], axis=1)\n",
    "x_test = pd.concat([x_test, new_x_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 확인\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid 확인\n",
    "x_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 확인\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨값 스케일링\n",
    "y_train = np.log(y_train)\n",
    "y_valid = np.log(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 모델 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) 모델 불러오기 및 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb_regr = XGBRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) 모델 학습하기 (훈련 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) 결과 예측하기 (검증 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_regr.predict(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) 결과 살펴보기\n",
    "일반적으로 선형회귀 R<sup>2</sup>를 평가 척도로 사용합니다.<br>\n",
    "R<sup>2</sup>값이 1에 가까울수록 회귀 모델이 데이터를 잘 표현한다는 것을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('XGBoost 회귀, R2 : {:.4f}'.format(r2_score(y_valid, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) 모델 불러오기 및 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "lgb_regr = LGBMRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) 모델 학습하기 (훈련 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) 결과 예측하기 (검증 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_regr.predict(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) 결과 살펴보기\n",
    "일반적으로 선형회귀 R<sup>2</sup>를 평가 척도로 사용합니다.<br>\n",
    "R<sup>2</sup>값이 1에 가까울수록 회귀 모델이 데이터를 잘 표현한다는 것을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LightGBM 회귀, R2 : {:.4f}'.format(r2_score(y_valid, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평가 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost ver\n",
    "regr = XGBRegressor(n_estimators=1000,\n",
    "                    max_depth=8)\n",
    "\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r2_score : {:.3f}'.format(r2_score(y_valid, y_pred)))\n",
    "print('MAE      : {:.6f}'.format(mean_absolute_error(y_valid, y_pred)))\n",
    "print('MSE      : {:.6f}'.format(mean_squared_error(y_valid, y_pred)))\n",
    "print('RMSE     : {:.6f}'.format(np.sqrt(mean_squared_error(y_valid, y_pred))))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_03) Regression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
